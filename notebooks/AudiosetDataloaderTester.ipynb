{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45104f35-df5a-4875-b784-ac1825745278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/u/li19/diffusers_with_dataloader/examples/audio_generation/audio_gen_files\")\n",
    "from AudiosetDataset import AudiosetDataset\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "from transformers import AutoTokenizer, T5EncoderModel,T5TokenizerFast\n",
    "\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "# device = \"cuda\"\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a5a4068-773f-4878-908c-f512858d25a7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type clap_text_model to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at cvssp/audioldm-m-full were not used when initializing T5EncoderModel: ['text_model.encoder.layer.1.output.LayerNorm.weight', 'text_model.encoder.layer.6.attention.output.LayerNorm.weight', 'text_model.encoder.layer.8.output.LayerNorm.weight', 'text_model.encoder.layer.0.attention.self.value.bias', 'text_model.encoder.layer.5.attention.output.dense.weight', 'text_model.encoder.layer.6.attention.self.query.weight', 'text_model.encoder.layer.4.output.LayerNorm.weight', 'text_model.encoder.layer.5.attention.output.LayerNorm.bias', 'text_projection.linear1.bias', 'text_model.encoder.layer.2.intermediate.dense.bias', 'text_model.encoder.layer.8.attention.self.value.weight', 'text_model.encoder.layer.9.output.LayerNorm.weight', 'text_model.encoder.layer.5.attention.self.value.weight', 'text_model.encoder.layer.5.output.LayerNorm.bias', 'text_model.encoder.layer.6.attention.output.dense.bias', 'text_model.encoder.layer.7.output.dense.weight', 'text_model.encoder.layer.3.intermediate.dense.bias', 'text_model.encoder.layer.11.attention.self.key.bias', 'text_model.encoder.layer.9.attention.self.query.bias', 'text_model.encoder.layer.7.attention.self.query.weight', 'text_model.encoder.layer.7.attention.self.value.weight', 'text_model.encoder.layer.9.attention.output.dense.weight', 'text_model.encoder.layer.3.output.LayerNorm.bias', 'text_model.encoder.layer.10.intermediate.dense.weight', 'text_model.encoder.layer.11.attention.self.value.weight', 'text_model.encoder.layer.5.output.dense.weight', 'text_model.encoder.layer.10.attention.self.query.bias', 'text_model.encoder.layer.9.attention.output.dense.bias', 'text_model.encoder.layer.3.output.dense.weight', 'text_model.encoder.layer.1.attention.self.value.weight', 'text_model.pooler.dense.weight', 'text_model.encoder.layer.0.output.LayerNorm.weight', 'text_model.encoder.layer.2.attention.self.value.bias', 'text_model.encoder.layer.2.output.dense.weight', 'text_model.encoder.layer.5.attention.self.key.weight', 'text_model.encoder.layer.4.attention.self.key.bias', 'text_model.encoder.layer.10.attention.self.value.bias', 'text_model.encoder.layer.11.attention.output.LayerNorm.weight', 'text_model.encoder.layer.6.attention.self.value.weight', 'text_model.encoder.layer.1.output.dense.bias', 'text_model.encoder.layer.9.attention.self.value.weight', 'text_model.encoder.layer.4.intermediate.dense.weight', 'text_model.encoder.layer.4.attention.self.value.bias', 'text_model.encoder.layer.11.attention.output.LayerNorm.bias', 'text_model.encoder.layer.9.intermediate.dense.weight', 'text_model.encoder.layer.9.output.dense.bias', 'text_model.encoder.layer.0.output.dense.bias', 'text_model.embeddings.position_ids', 'text_model.encoder.layer.6.attention.output.dense.weight', 'text_model.encoder.layer.8.attention.self.key.weight', 'text_model.encoder.layer.11.output.LayerNorm.bias', 'text_model.encoder.layer.8.output.dense.weight', 'text_model.encoder.layer.8.output.LayerNorm.bias', 'text_model.encoder.layer.6.output.LayerNorm.weight', 'text_model.encoder.layer.10.intermediate.dense.bias', 'text_model.encoder.layer.11.attention.self.query.bias', 'text_model.embeddings.LayerNorm.bias', 'text_model.encoder.layer.10.attention.self.query.weight', 'text_model.encoder.layer.7.attention.output.dense.weight', 'text_model.encoder.layer.11.intermediate.dense.weight', 'text_model.encoder.layer.8.attention.output.LayerNorm.bias', 'text_model.encoder.layer.5.intermediate.dense.bias', 'text_model.encoder.layer.0.attention.self.key.weight', 'text_model.encoder.layer.4.intermediate.dense.bias', 'text_model.encoder.layer.5.attention.self.query.bias', 'text_model.encoder.layer.7.intermediate.dense.bias', 'text_model.encoder.layer.9.attention.self.query.weight', 'text_model.encoder.layer.9.attention.output.LayerNorm.bias', 'text_model.encoder.layer.7.attention.self.key.bias', 'text_model.encoder.layer.3.output.LayerNorm.weight', 'text_model.encoder.layer.4.attention.output.LayerNorm.bias', 'text_model.encoder.layer.3.attention.self.key.weight', 'text_model.encoder.layer.1.attention.self.key.weight', 'text_model.encoder.layer.2.attention.self.value.weight', 'text_model.encoder.layer.4.attention.self.value.weight', 'text_model.encoder.layer.5.intermediate.dense.weight', 'text_model.encoder.layer.6.attention.self.key.bias', 'text_model.encoder.layer.5.output.dense.bias', 'text_model.encoder.layer.8.attention.self.value.bias', 'text_model.encoder.layer.2.output.LayerNorm.bias', 'text_model.encoder.layer.8.attention.output.dense.bias', 'text_model.encoder.layer.1.intermediate.dense.bias', 'text_model.encoder.layer.1.attention.output.dense.bias', 'text_model.encoder.layer.4.attention.self.query.weight', 'text_model.embeddings.token_type_embeddings.weight', 'text_model.encoder.layer.11.output.dense.weight', 'text_model.encoder.layer.1.intermediate.dense.weight', 'text_model.encoder.layer.7.attention.output.LayerNorm.bias', 'text_model.encoder.layer.0.attention.self.value.weight', 'text_model.encoder.layer.8.intermediate.dense.weight', 'text_model.encoder.layer.3.intermediate.dense.weight', 'text_model.encoder.layer.5.attention.self.query.weight', 'text_model.encoder.layer.1.attention.self.query.bias', 'text_model.encoder.layer.0.attention.self.query.weight', 'text_model.encoder.layer.4.output.dense.weight', 'text_model.encoder.layer.6.output.dense.bias', 'text_model.encoder.layer.7.attention.output.LayerNorm.weight', 'text_model.encoder.layer.1.attention.self.query.weight', 'text_model.encoder.layer.0.intermediate.dense.weight', 'text_model.encoder.layer.3.attention.output.dense.bias', 'text_model.encoder.layer.2.attention.output.LayerNorm.weight', 'text_model.encoder.layer.3.attention.self.key.bias', 'text_model.encoder.layer.8.attention.self.query.weight', 'text_model.encoder.layer.9.attention.self.key.bias', 'text_model.encoder.layer.3.attention.self.query.bias', 'text_model.encoder.layer.0.attention.output.dense.weight', 'text_model.encoder.layer.4.output.LayerNorm.bias', 'text_model.encoder.layer.10.output.dense.weight', 'text_model.encoder.layer.11.attention.output.dense.bias', 'text_projection.linear2.bias', 'text_model.encoder.layer.2.attention.self.key.bias', 'text_model.encoder.layer.2.intermediate.dense.weight', 'text_model.embeddings.LayerNorm.weight', 'text_model.encoder.layer.3.attention.output.LayerNorm.bias', 'text_model.encoder.layer.11.attention.self.value.bias', 'text_model.encoder.layer.10.attention.self.key.weight', 'text_model.embeddings.token_type_ids', 'text_model.encoder.layer.10.attention.self.key.bias', 'text_model.encoder.layer.1.output.LayerNorm.bias', 'text_model.encoder.layer.7.intermediate.dense.weight', 'text_model.encoder.layer.8.intermediate.dense.bias', 'text_model.encoder.layer.11.attention.output.dense.weight', 'text_model.encoder.layer.8.output.dense.bias', 'text_model.encoder.layer.4.attention.output.dense.bias', 'text_model.encoder.layer.2.attention.self.query.bias', 'text_model.encoder.layer.4.attention.output.dense.weight', 'text_model.encoder.layer.7.attention.self.key.weight', 'text_model.encoder.layer.8.attention.self.query.bias', 'text_model.encoder.layer.7.attention.self.value.bias', 'text_model.encoder.layer.5.attention.self.key.bias', 'text_model.encoder.layer.10.attention.output.dense.bias', 'text_model.encoder.layer.10.output.LayerNorm.bias', 'text_model.encoder.layer.0.attention.self.query.bias', 'text_model.encoder.layer.6.intermediate.dense.weight', 'text_model.embeddings.position_embeddings.weight', 'text_model.encoder.layer.11.output.dense.bias', 'text_model.encoder.layer.7.attention.output.dense.bias', 'text_model.encoder.layer.9.intermediate.dense.bias', 'text_model.encoder.layer.1.attention.self.key.bias', 'text_model.encoder.layer.8.attention.output.LayerNorm.weight', 'text_model.encoder.layer.2.attention.output.LayerNorm.bias', 'text_model.encoder.layer.5.attention.output.LayerNorm.weight', 'text_model.encoder.layer.0.attention.self.key.bias', 'text_model.encoder.layer.9.output.dense.weight', 'text_model.encoder.layer.0.intermediate.dense.bias', 'text_model.encoder.layer.10.output.LayerNorm.weight', 'text_model.encoder.layer.7.output.LayerNorm.weight', 'text_model.encoder.layer.1.output.dense.weight', 'text_model.encoder.layer.0.output.LayerNorm.bias', 'text_model.encoder.layer.3.attention.output.dense.weight', 'text_model.encoder.layer.1.attention.output.dense.weight', 'text_model.encoder.layer.6.attention.self.value.bias', 'text_model.encoder.layer.2.attention.output.dense.weight', 'text_projection.linear2.weight', 'text_model.encoder.layer.1.attention.output.LayerNorm.bias', 'text_model.encoder.layer.9.attention.output.LayerNorm.weight', 'text_model.encoder.layer.5.output.LayerNorm.weight', 'text_model.encoder.layer.3.attention.self.query.weight', 'text_model.encoder.layer.4.output.dense.bias', 'text_model.encoder.layer.11.attention.self.key.weight', 'text_model.encoder.layer.6.output.LayerNorm.bias', 'text_model.encoder.layer.10.attention.output.LayerNorm.bias', 'text_model.encoder.layer.6.output.dense.weight', 'text_model.encoder.layer.11.output.LayerNorm.weight', 'text_model.pooler.dense.bias', 'text_model.encoder.layer.3.output.dense.bias', 'text_model.encoder.layer.2.output.LayerNorm.weight', 'text_model.encoder.layer.8.attention.output.dense.weight', 'text_model.encoder.layer.4.attention.self.key.weight', 'text_model.encoder.layer.11.attention.self.query.weight', 'text_model.encoder.layer.4.attention.self.query.bias', 'text_model.encoder.layer.6.intermediate.dense.bias', 'text_model.encoder.layer.5.attention.self.value.bias', 'text_model.encoder.layer.0.attention.output.dense.bias', 'text_model.encoder.layer.6.attention.self.key.weight', 'text_model.encoder.layer.0.attention.output.LayerNorm.bias', 'text_model.encoder.layer.3.attention.self.value.bias', 'text_model.embeddings.word_embeddings.weight', 'text_model.encoder.layer.1.attention.self.value.bias', 'text_model.encoder.layer.1.attention.output.LayerNorm.weight', 'text_model.encoder.layer.10.output.dense.bias', 'text_model.encoder.layer.0.output.dense.weight', 'text_model.encoder.layer.3.attention.output.LayerNorm.weight', 'text_model.encoder.layer.4.attention.output.LayerNorm.weight', 'text_model.encoder.layer.9.attention.self.key.weight', 'text_model.encoder.layer.3.attention.self.value.weight', 'text_model.encoder.layer.10.attention.self.value.weight', 'text_model.encoder.layer.6.attention.self.query.bias', 'text_projection.linear1.weight', 'text_model.encoder.layer.2.attention.output.dense.bias', 'text_model.encoder.layer.7.output.dense.bias', 'text_model.encoder.layer.11.intermediate.dense.bias', 'text_model.encoder.layer.7.output.LayerNorm.bias', 'text_model.encoder.layer.10.attention.output.LayerNorm.weight', 'text_model.encoder.layer.2.attention.self.key.weight', 'text_model.encoder.layer.6.attention.output.LayerNorm.bias', 'text_model.encoder.layer.8.attention.self.key.bias', 'text_model.encoder.layer.9.attention.self.value.bias', 'text_model.encoder.layer.10.attention.output.dense.weight', 'text_model.encoder.layer.7.attention.self.query.bias', 'text_model.encoder.layer.2.attention.self.query.weight', 'text_model.encoder.layer.0.attention.output.LayerNorm.weight', 'text_model.encoder.layer.9.output.LayerNorm.bias', 'text_model.encoder.layer.2.output.dense.bias', 'text_model.encoder.layer.5.attention.output.dense.bias']\n",
      "- This IS expected if you are initializing T5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of T5EncoderModel were not initialized from the model checkpoint at cvssp/audioldm-m-full and are newly initialized: ['encoder.block.7.layer.0.layer_norm.weight', 'encoder.block.7.layer.1.DenseReluDense.wi.weight', 'encoder.block.0.layer.1.DenseReluDense.wo.weight', 'encoder.block.9.layer.1.layer_norm.weight', 'encoder.block.11.layer.1.DenseReluDense.wi.weight', 'encoder.block.9.layer.0.SelfAttention.k.weight', 'encoder.block.11.layer.1.layer_norm.weight', 'encoder.block.3.layer.1.DenseReluDense.wi.weight', 'encoder.block.1.layer.1.DenseReluDense.wo.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.11.layer.1.DenseReluDense.wo.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.1.DenseReluDense.wo.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.11.layer.0.SelfAttention.k.weight', 'encoder.block.11.layer.0.SelfAttention.q.weight', 'encoder.block.8.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.8.layer.1.DenseReluDense.wi.weight', 'encoder.block.6.layer.1.DenseReluDense.wi.weight', 'encoder.block.0.layer.0.layer_norm.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.1.DenseReluDense.wi.weight', 'encoder.block.5.layer.1.DenseReluDense.wo.weight', 'encoder.block.9.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.7.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.11.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.1.layer_norm.weight', 'encoder.block.1.layer.0.layer_norm.weight', 'encoder.block.6.layer.1.layer_norm.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'encoder.block.9.layer.1.DenseReluDense.wi.weight', 'encoder.final_layer_norm.weight', 'encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.9.layer.0.layer_norm.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.8.layer.0.SelfAttention.k.weight', 'encoder.block.6.layer.0.SelfAttention.v.weight', 'encoder.block.10.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.8.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.block.10.layer.1.DenseReluDense.wi.weight', 'encoder.block.11.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.1.DenseReluDense.wo.weight', 'encoder.block.5.layer.0.layer_norm.weight', 'encoder.block.6.layer.0.SelfAttention.q.weight', 'shared.weight', 'encoder.block.1.layer.1.layer_norm.weight', 'encoder.block.3.layer.0.layer_norm.weight', 'encoder.block.7.layer.1.layer_norm.weight', 'encoder.block.6.layer.0.layer_norm.weight', 'encoder.block.3.layer.1.layer_norm.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.9.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.layer_norm.weight', 'encoder.block.10.layer.0.layer_norm.weight', 'encoder.block.4.layer.1.DenseReluDense.wo.weight', 'encoder.block.1.layer.1.DenseReluDense.wi.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.8.layer.0.layer_norm.weight', 'encoder.block.10.layer.1.DenseReluDense.wo.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.1.DenseReluDense.wi.weight', 'encoder.block.6.layer.1.DenseReluDense.wo.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.9.layer.1.DenseReluDense.wo.weight', 'encoder.block.0.layer.1.DenseReluDense.wi.weight', 'encoder.block.9.layer.0.SelfAttention.q.weight', 'encoder.block.6.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.1.layer_norm.weight', 'encoder.block.8.layer.1.layer_norm.weight', 'encoder.block.4.layer.1.DenseReluDense.wi.weight', 'encoder.block.7.layer.0.SelfAttention.v.weight', 'encoder.block.10.layer.1.layer_norm.weight', 'encoder.block.10.layer.0.SelfAttention.o.weight', 'encoder.block.5.layer.1.layer_norm.weight', 'encoder.block.7.layer.1.DenseReluDense.wo.weight', 'encoder.block.4.layer.0.layer_norm.weight', 'encoder.block.2.layer.1.layer_norm.weight', 'encoder.block.6.layer.0.SelfAttention.o.weight', 'encoder.block.10.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.8.layer.1.DenseReluDense.wo.weight', 'encoder.block.10.layer.0.SelfAttention.k.weight', 'encoder.block.11.layer.0.layer_norm.weight', 'encoder.block.7.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.7.layer.0.SelfAttention.q.weight', 'encoder.block.8.layer.0.SelfAttention.o.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cvssp/audioldm-m-full\", model_max_length=512,  subfolder=\"tokenizer\")\n",
    "text_encoder = T5EncoderModel.from_pretrained(\"cvssp/audioldm-m-full\", subfolder=\"text_encoder\")\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"t5-large\", model_max_length=512)\n",
    "# text_encoder = T5EncoderModel.from_pretrained(\"t5-large\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "736d4720-9f43-4b49-ac17-c86e89be147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_json_file = \"/u/li19/data_folder/AudioTaggingDoneRight/egs/audioset/data/datafiles/delta_bal_alpaca_train.json\"\n",
    "\n",
    "bal_audio_conf = \"/u/li19/diffusers_with_dataloader/examples/audio_generation/audio_gen_files/audio_conf_latents-tmp.json\"\n",
    "with open(bal_audio_conf, \"r\") as f:\n",
    "    audio_set_data_file = json.load(f)\n",
    "latent_folder = \"/u/li19/data_folder/AudioTaggingDoneRight/egs/audioset/data/datafiles/bal_latent_raw\"\n",
    "wav_folder = \"/u/li19/data_folder/audioSetAudio/balance_wav\"\n",
    "batch_size = 10\n",
    "sampler=None\n",
    "num_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7dd5022-8d10-47db-87c5-29743e6fca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AudiosetDataset(\n",
    "    audio_set_data_file, \n",
    "    latent_folder=latent_folder, \n",
    "    tokenizer=tokenizer, \n",
    "    device=device, \n",
    "    wav_folder=wav_folder,\n",
    "    dtype=torch.float32,\n",
    "    channels=1,\n",
    ")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffa25f6f-92f0-45c8-bb9e-803fb532bfe9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "torch.Size([10, 1, 8, 504])\n",
      "torch.Size([10, 512])\n",
      "10\n",
      "tensor([   0,   83,  621,   16, 2686,  150,   89,   16,   10, 7337,  821, 3810,\n",
      "           9,  935,    4, 1437,    2,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1])\n",
      "tokens:  tensor([   0,   83,  621,   16, 2686,  150,   89,   16,   10, 7337,  821, 3810,\n",
      "           9,  935,    4, 1437,    2,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1], dtype=torch.int32)\n",
      "torch.Size([10, 512, 768])\n"
     ]
    }
   ],
   "source": [
    "for step, batch in enumerate(dataloader):\n",
    "    if step > 0:\n",
    "        break\n",
    "    print(batch['latent'].shape)\n",
    "    # print(batch)\n",
    "    print(batch['input_ids'].shape)\n",
    "    print(len(batch['caption']))\n",
    "    label = batch['caption'][0]\n",
    "    encoder_hidden_states = text_encoder(batch[\"input_ids\"])[0]\n",
    "    input_ids = []\n",
    "    input_ids = tokenizer(\n",
    "        [label], max_length=tokenizer.model_max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids = input_ids.input_ids[0]\n",
    "    print(input_ids)\n",
    "    print('tokens: ', batch['input_ids'][0])\n",
    "    print(encoder_hidden_states.shape)\n",
    "    # print(encoder_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93522a45-151a-4199-bcc1-9ec357710e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cff667-fb31-42a3-9dc8-3d5fcca8a8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = torch.utils.data.DataLoader( \n",
    "        AudiosetDataset(data, tokenizer=tokenizer, device=accelerator.device, dtype=weight_dtype, logger=logger, channels=1),\n",
    "        batch_size=args.train_batch_size, sampler=sampler, num_workers=args.dataloader_num_workers, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17629c88-b621-443f-b82f-4acf11af3436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/li19/data_folder/anaconda3/envs/diffuse/lib/python3.10/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StableDiffusionPipeline {\n",
       "  \"_class_name\": \"StableDiffusionPipeline\",\n",
       "  \"_diffusers_version\": \"0.15.1\",\n",
       "  \"feature_extractor\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPFeatureExtractor\"\n",
       "  ],\n",
       "  \"requires_safety_checker\": true,\n",
       "  \"safety_checker\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"PNDMScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"unet\": [\n",
       "    \"diffusers\",\n",
       "    \"UNet2DConditionModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"CompVis/stable-diffusion-v1-4\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_path, device_map=None, safety_checker=None)\n",
    "pipe.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4065b0f0-c9a5-4b9e-895c-8de74db6072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_json_file = \"/u/li19/data_folder/AudioTaggingDoneRight/egs/audioset/data/datafiles/delta_bal_alpaca_train.json\"\n",
    "latent_folder = \"/u/li19/data_folder/AudioTaggingDoneRight/egs/audioset/data/datafiles/bal_latent_raw\"\n",
    "wav_folder = \"/u/li19/data_folder/audioSetAudio/balance_wav\"\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\n",
    "\"CompVis/stable-diffusion-v1-4\", subfolder=\"tokenizer\"\n",
    "    )\n",
    "\n",
    "dataset = AudiosetDataset(\n",
    "    dataset_json_file, \n",
    "    latent_folder=latent_folder, \n",
    "    tokenizer=tokenizer, \n",
    "    device=device, \n",
    "    wav_folder=wav_folder,\n",
    "    dtype=torch.float32,\n",
    "    channels=4\n",
    ")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f566ab2b-c612-4c12-861f-4ecfb6c4bbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 504])\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[0]\n",
    "latent = sample[\"latent\"]\n",
    "print(latent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6825bb8b-37e6-4103-a14e-6ebfb279b03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 8, 504])\n",
      "torch.Size([6, 8, 21, 24])\n",
      "torch.Size([6])\n",
      "torch.Size([6, 77, 768])\n"
     ]
    }
   ],
   "source": [
    "n = 6\n",
    "\n",
    "og_noise = torch.randn([n, 1, 8, 504]).to(device)\n",
    "\n",
    "noise = torch.randn((n, 8, 21, 24)).to(device)\n",
    "\n",
    "t_steps= torch.randn([n]).to(device)\n",
    "\n",
    "fake_embeds = torch.randn([n, 77, 768]).to(device)\n",
    "\n",
    "\n",
    "\n",
    "print(og_noise.shape)\n",
    "print(noise.shape)\n",
    "print(t_steps.shape)\n",
    "print(fake_embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19ad6056-a03e-43f6-a10d-d01cb0d25903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: torch.Size([6, 1, 8, 504])\n",
      "PRE_FIRST_CONV: torch.Size([6, 8, 21, 24])\n",
      "POST_FIRST_CONV: torch.Size([6, 320, 21, 24])\n",
      "DOWN:  torch.Size([6, 320, 11, 12])\n",
      "DOWN:  torch.Size([6, 640, 6, 6])\n",
      "DOWN:  torch.Size([6, 1280, 3, 3])\n",
      "DOWN:  torch.Size([6, 1280, 3, 3])\n",
      "MID:  torch.Size([6, 1280, 3, 3])\n",
      "UP:  torch.Size([6, 1280, 6, 6])\n",
      "UP:  torch.Size([6, 1280, 11, 12])\n",
      "UP:  torch.Size([6, 640, 21, 24])\n",
      "UP:  torch.Size([6, 320, 21, 24])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 8, 504])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing if our reshape works in the unet\n",
    "\n",
    "\n",
    "og_recon = pipe.unet(og_noise, t_steps, fake_embeds).sample\n",
    "og_recon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de24980-6666-46d3-9c0a-e4e11442156a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2233f47f-0b62-4fb0-bfc7-ae20baf7690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_conv = torch.nn.Conv2d(8, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)).to(device)\n",
    "\n",
    "conv_out_kernel = 3\n",
    "conv_out_padding = (conv_out_kernel - 1) // 2\n",
    "new_conv_out = torch.nn.Conv2d(320, 8, kernel_size=conv_out_kernel, padding=conv_out_padding).to(device)\n",
    "\n",
    "pipe.unet.conv_in = new_conv\n",
    "pipe.unet.conv_out = new_conv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4d35bf1-79b1-4a3f-8efc-f85fef2bdead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE_FIRST_CONV: torch.Size([6, 8, 21, 24])\n",
      "POST_FIRST_CONV: torch.Size([6, 320, 21, 24])\n",
      "DOWN:  torch.Size([6, 320, 11, 12])\n",
      "DOWN:  torch.Size([6, 640, 6, 6])\n",
      "DOWN:  torch.Size([6, 1280, 3, 3])\n",
      "DOWN:  torch.Size([6, 1280, 3, 3])\n",
      "MID:  torch.Size([6, 1280, 3, 3])\n",
      "UP:  torch.Size([6, 1280, 6, 6])\n",
      "UP:  torch.Size([6, 1280, 11, 12])\n",
      "UP:  torch.Size([6, 640, 21, 24])\n",
      "UP:  torch.Size([6, 320, 21, 24])\n",
      "OUT:  torch.Size([6, 8, 21, 24])\n"
     ]
    }
   ],
   "source": [
    "new_recon = pipe.unet(noise, t_steps, fake_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cce1263c-4aff-453d-ba13-98f6b4dc2545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIAS - FROM:  torch.Size([320]) TO:  torch.Size([320])\n",
      "FROM:  torch.Size([320, 4, 3, 3]) TO:  torch.Size([320, 8, 3, 3]) WITH:  torch.Size([320, 8, 3, 3])\n",
      "BIAS - FROM:  torch.Size([4]) TO:  torch.Size([8])\n",
      "FROM:  torch.Size([4, 320, 3, 3]) TO:  torch.Size([8, 320, 3, 3]) WITH:  torch.Size([8, 320, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "def copy_weights(source, dest, channel=1):\n",
    "    # Get the weights and biases from the smaller convolutional layer\n",
    "    source_weights = source.state_dict()['weight']\n",
    "    source_biases = source.state_dict()['bias']\n",
    "\n",
    "    dest_weights = dest.state_dict()['weight']\n",
    "    dest_biases = dest.state_dict()['bias']\n",
    "    \n",
    "    # Here, we duplicate the weights along the input channels dimension\n",
    "    dest_weights_new = torch.cat((source_weights, source_weights), dim=channel)\n",
    "    if (channel != 1):\n",
    "        dest_bias_new = torch.cat((source_biases, source_biases))\n",
    "    else:\n",
    "        dest_bias_new = source_biases\n",
    "    \n",
    "    print(\"BIAS - FROM: \", source_biases.shape, \"TO: \", dest_biases.shape)\n",
    "    print(\"FROM: \", source_weights.shape, \"TO: \", dest_weights.shape, \"WITH: \", dest_weights_new.shape)\n",
    "    \n",
    "    \n",
    "    dest.load_state_dict({'weight': dest_weights_new, 'bias': dest_bias_new})\n",
    "    return dest\n",
    "\n",
    "model_path = \"CompVis/stable-diffusion-v1-4\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_path, device_map=None, safety_checker=None)\n",
    "\n",
    "\n",
    "small_conv_in = pipe.unet.conv_in\n",
    "large_conv_in = torch.nn.Conv2d(8, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "\n",
    "\n",
    "small_conv_out = pipe.unet.conv_out\n",
    "\n",
    "conv_out_kernel = 3\n",
    "conv_out_padding = (conv_out_kernel - 1) // 2\n",
    "large_conv_out = torch.nn.Conv2d(320, 8, kernel_size=conv_out_kernel, padding=conv_out_padding)\n",
    "\n",
    "large_conv_in = copy_weights(small_conv_in, large_conv_in)\n",
    "large_conv_out = copy_weights(small_conv_out, large_conv_out, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92c1a01d-ab6e-44b7-91c2-05d32709ad1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.unet.conv_in = large_conv_in\n",
    "pipe.unet.conv_out = large_conv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1957ff46-909f-4c1c-801e-4d9a03dec4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.save_pretrained(\"/u/li19/data_folder/model_cache/audio_journey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169a95b0-8fbb-4390-8439-53403392b769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2615fc97-d569-42d3-bff5-5ddcd4b4b97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StableDiffusionPipeline {\n",
       "  \"_class_name\": \"StableDiffusionPipeline\",\n",
       "  \"_diffusers_version\": \"0.15.1\",\n",
       "  \"feature_extractor\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPFeatureExtractor\"\n",
       "  ],\n",
       "  \"requires_safety_checker\": true,\n",
       "  \"safety_checker\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"PNDMScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"unet\": [\n",
       "    \"diffusers\",\n",
       "    \"UNet2DConditionModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"/u/li19/data_folder/model_cache/audio_journey\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_path, device_map=None, safety_checker=None)\n",
    "pipe.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1601e9ed-34ca-4969-b38b-8a929d7b98ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a21d1e0f1d94813a56f5d534fbbdfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen = pipe(prompt=\"idk whatever it does not matter\", width=504, height=8, num_inference_steps=400, output_type=\"latent\").images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58b28614-1582-4260-8590-3e325d010233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 504])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f396e268640>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(gen.shape)\n",
    "\n",
    "plt.imshow(gen[0, :, :200].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a348bb5-9005-49de-9e07-27198fb9760e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMALL - weights: torch.Size([320, 4, 3, 3]), biases: torch.Size([320])\n",
      "LARGE - weights: torch.Size([320, 8, 3, 3]), biases: torch.Size([320])\n"
     ]
    }
   ],
   "source": [
    "# Get the weights and biases from the smaller convolutional layer\n",
    "small_weights = small_conv.state_dict()['weight']\n",
    "small_biases = small_conv.state_dict()['bias']\n",
    "\n",
    "large_weights = large_conv.state_dict()['weight']\n",
    "large_biases = large_conv.state_dict()['bias']\n",
    "\n",
    "\n",
    "print(f'SMALL - weights: {small_weights.shape}, biases: {small_biases.shape}')\n",
    "\n",
    "print(f'LARGE - weights: {large_weights.shape}, biases: {large_biases.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28d29312-096f-4466-80ec-3d281ae608e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320, 8, 3, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Modify the weights to match the shape of the larger convolutional layer\n",
    "# Here, we duplicate the weights along the input channels dimension\n",
    "large_weights_new = torch.cat((small_weights, small_weights), dim=1)\n",
    "large_weights_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e987f-1c98-4ecc-ae24-634db7438d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the modified weights and biases into the larger convolutional layer\n",
    "large_conv.load_state_dict({'weight': large_weights_new, 'bias': small_biases})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7430b7f7-2fed-4f0d-87f3-894e4c7b0fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_in = torch.randn([1, 8, 504])\n",
    "reshaped = torch.Tensor.view(rand_in, [1, 8, 21, 24])\n",
    "recon = torch.Tensor.view(reshaped, [1, 8, 504])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ce2fd37-d4ba-4adc-8754-b05e368dd064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 504])\n",
      "torch.Size([1, 8, 21, 24])\n",
      "torch.Size([1, 8, 504])\n"
     ]
    }
   ],
   "source": [
    "print(rand_in.shape)\n",
    "print(reshaped.shape)\n",
    "print(recon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4fe1394-86be-468c-9c93-bf0a01ed051c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(rand_in.eq(recon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d63a288-d814-407b-8b8b-408736c76f71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffuse",
   "language": "python",
   "name": "diffuse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
