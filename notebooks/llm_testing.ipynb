{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f36be5e1-7a39-4327-a5cc-7fd6db479747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/li19/anaconda3/envs/diffuse/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LlamaForCausalLM' from 'transformers' (/u/li19/anaconda3/envs/diffuse/lib/python3.10/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlamaForCausalLM, LlamaTokenizer\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'LlamaForCausalLM' from 'transformers' (/u/li19/anaconda3/envs/diffuse/lib/python3.10/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a56a08b-bf0d-48a8-ae19-4598cb757748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|████████████████████████████████████████████████████████████████████████| 819/819 [00:00<00:00, 1.70MB/s]\n",
      "Downloading (…)instruct_pipeline.py: 100%|████████████████████████████████████████████████████████████████████| 7.16k/7.16k [00:00<00:00, 14.7MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████████████████████████████████████████████████████████████████████| 23.8G/23.8G [08:59<00:00, 44.2MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|████████████████████████████████████████████████████████████████████████| 449/449 [00:00<00:00, 1.13MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|████████████████████████████████████████████████████████████████████| 2.11M/2.11M [00:00<00:00, 15.3MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|█████████████████████████████████████████████████████████████████████████| 228/228 [00:00<00:00, 559kB/s]\n"
     ]
    }
   ],
   "source": [
    "generate_text = pipeline(model=\"databricks/dolly-v2-12b\", torch_dtype=torch.bfloat16, trust_remote_code=True, device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c51b5515-8983-476f-8310-1784e9d6185c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside, a small room, a dog was barking, howling and speeching along with Rub\n"
     ]
    }
   ],
   "source": [
    "prompt = '''For each of the 3 line summarize the sounds into a single sentence: \n",
    "imagine a scene with all of these sounds existing together: (inside, small room).\n",
    " > This is happening inside a small room. \n",
    "\n",
    "imagine a scene with all of these sounds existing together: (dog, bark, howl, speech).\n",
    " > a dog barking and howling with a person speaking aswell. \n",
    "\n",
    "imagine a scene with all of these sounds existing together: (Sanding, and Rub). \n",
    " > '''\n",
    "\n",
    "ans = generate_text(prompt)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "914ebb71-7b73-4fc2-b11f-dabf6c81286d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|█████████████████████████████████████████████████████████████████████████| 141/141 [00:00<00:00, 170kB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 tokenizer = AutoTokenizer.from_pretrained(<span style=\"color: #808000; text-decoration-color: #808000\">\"decapoda-research/llama-7b-hf\"</span>)                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>model = AutoModelForCausalLM.from_pretrained(<span style=\"color: #808000; text-decoration-color: #808000\">\"decapoda-research/llama-7b-hf\"</span>)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/u/li19/anaconda3/envs/diffuse/lib/python3.10/site-packages/transformers/models/auto/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tokenizatio</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">n_auto.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">676</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">673 │   │   │   │   </span>tokenizer_class = tokenizer_class_from_name(tokenizer_class_candidate)     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">674 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">675 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> tokenizer_class <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>676 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">677 │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"Tokenizer class {</span>tokenizer_class_candidate<span style=\"color: #808000; text-decoration-color: #808000\">} does not exist or is n</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">678 │   │   │   │   </span>)                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">679 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> tokenizer_class.from_pretrained(pretrained_model_name_or_path, *input   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>Tokenizer class LLaMATokenizer does not exist or is not currently imported.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 tokenizer = AutoTokenizer.from_pretrained(\u001b[33m\"\u001b[0m\u001b[33mdecapoda-research/llama-7b-hf\u001b[0m\u001b[33m\"\u001b[0m)                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0mmodel = AutoModelForCausalLM.from_pretrained(\u001b[33m\"\u001b[0m\u001b[33mdecapoda-research/llama-7b-hf\u001b[0m\u001b[33m\"\u001b[0m)                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/u/li19/anaconda3/envs/diffuse/lib/python3.10/site-packages/transformers/models/auto/\u001b[0m\u001b[1;33mtokenizatio\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mn_auto.py\u001b[0m:\u001b[94m676\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m673 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mtokenizer_class = tokenizer_class_from_name(tokenizer_class_candidate)     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m674 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m675 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m tokenizer_class \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m676 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m677 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mTokenizer class \u001b[0m\u001b[33m{\u001b[0mtokenizer_class_candidate\u001b[33m}\u001b[0m\u001b[33m does not exist or is n\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m678 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m679 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m tokenizer_class.from_pretrained(pretrained_model_name_or_path, *input   \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0mTokenizer class LLaMATokenizer does not exist or is not currently imported.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"/output/path\")\n",
    "model = LlamaForCausalLM.from_pretrained(\"/output/path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50bbece-0bd8-4e29-ab9d-d86fa417ddc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffuse",
   "language": "python",
   "name": "diffuse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
