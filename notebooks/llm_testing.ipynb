{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
<<<<<<< HEAD
   "id": "f36be5e1-7a39-4327-a5cc-7fd6db479747",
=======
   "id": "09200e32-d9b4-42ac-ae68-53b49a033d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import llm_client\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d8ea333-cafa-44ba-b468-9e0e64465752",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_client = llm_client.Client(address=\"tir-1-18\", port=4340)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72973e47-2701-4da2-a142-da5529fc5950",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"What are the advantages and disadvantages of using international law to resolve disputes between states?\",\n",
    "    \"How has the recent rise of populism impacted the role of international law in global governance?\",\n",
    "    \"What are the legal implications of climate change and how can international law address them?\",\n",
    "    \"To what extent can international criminal law be an effective tool for deterring and punishing acts of terrorism?\",\n",
    "    \"How do human rights standards interact with national security concerns in the context of counterterrorism measures?\",\n",
    "    \"How can international law respond to the challenges posed by new and emerging technologies?\",\n",
    "    \"What is the role of international investment law in promoting economic development and protecting the rights of investors and host states?\",\n",
    "    \"How can international law address the issue of corruption and promote good governance?\",\n",
    "    \"What are the legal and ethical implications of artificial intelligence and machine learning in the legal profession?\",\n",
    "    \"How does international law regulate the use of force in self-defense and humanitarian intervention?\",\n",
    "    \"What are the implications of the ongoing refugee crisis for international refugee law and human rights?\",\n",
    "    \"How can international law address the challenges posed by transnational organized crime?\",\n",
    "    \"What is the role of international law in promoting and protecting the rights of indigenous peoples?\",\n",
    "    \"What are the legal and ethical implications of using drones in military and civilian contexts?\",\n",
    "    \"How can international law respond to the challenges posed by global health emergencies?\",\n",
    "    \"What is the role of international law in protecting the environment and promoting sustainable development?\",\n",
    "]\n",
    "\n",
    "\n",
    "n_prompts = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b34d9f75-930c-4e16-b4f2-c4905a27d82e",
>>>>>>> 3bb861fc4a6d27faba64b02f686a7e22bfdcd682
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "/u/li19/anaconda3/envs/diffuse/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LlamaForCausalLM' from 'transformers' (/u/li19/anaconda3/envs/diffuse/lib/python3.10/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlamaForCausalLM, LlamaTokenizer\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'LlamaForCausalLM' from 'transformers' (/u/li19/anaconda3/envs/diffuse/lib/python3.10/site-packages/transformers/__init__.py)"
=======
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:02<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.294408709914595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
>>>>>>> 3bb861fc4a6d27faba64b02f686a7e22bfdcd682
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "import torch\n",
    "# from transformers import pipeline\n",
    "# from transformers import LlamaForCausalLM, LlamaTokenizer\n"
=======
    "before = time.time()\n",
    "n = 5\n",
    "for i in tqdm(range(n)):\n",
    "    _ = alpaca_client.prompt(prompts[0], max_new_tokens=10)\n",
    "after = time.time()\n",
    "dt = after - before\n",
    "dt /= n\n",
    "dt *= 2_000_000\n",
    "mins = dt / 60\n",
    "hours = mins / 60\n",
    "days = hours / 24\n",
    "print(days)"
>>>>>>> 3bb861fc4a6d27faba64b02f686a7e22bfdcd682
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "id": "2a56a08b-bf0d-48a8-ae19-4598cb757748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)instruct_pipeline.py: 100%|██████████| 9.10k/9.10k [00:00<00:00, 19.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "generate_text = pipeline(model=\"databricks/dolly-v2-12b\", torch_dtype=torch.bfloat16, trust_remote_code=True, device_map=\"auto\")\n"
=======
   "execution_count": 26,
   "id": "3dfc4f3e-9000-4482-9064-86be63066d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_caption(classes, client):\n",
    "    human_sample = \", \".join(classes[:-2] + [\", and \".join(classes[-2:])])\n",
    "    prompt = \"\"\n",
    "    \n",
    "    \n",
    "    preface = \"describe a situation with all of these sounds together:\"\n",
    "    \n",
    "    \n",
    "    prompt += \"For each of the 3 line summarize the sounds into a single sentence: \\n\"\n",
    "    \n",
    "    prompt += preface + \" (alarm, burp, inside, small room).\" + \"\\n > burping while an alarm plays inside a small room. \\n\\n\"\n",
    "    \n",
    "    prompt += preface + \" (dog, bark, howl, speech).\" + \"\\n > a dog barking and howling with a person speaking aswell. \\n\\n\"\n",
    "    \n",
    "    prompt += preface + \" (Music, jazz, piano, singing, speaking).\" + \"\\n > a person plays jazz piano with a singer while people talk. \\n\\n\"\n",
    "    \n",
    "    prompt += preface + \" (engine, vehicle, wind, music, speech).\" + \"\\n > people talking inside a car while driving and listening to music. \\n\\n\"\n",
    "    \n",
    "    prompt += preface + \" (water, garggle, inside, small room).\" + \"\\n >air is passing through the water in their mouth in a small room with water. \\n\\n\"\n",
    "        \n",
    "    prompt += preface + \" (scratch, hammer, metal).\" + \"\\n > hammer striking a metal surface and scratching sounds can be heard \\n\\n\"\n",
    "        \n",
    "    prompt += preface + \" (thunder, wind, bark, small room).\" + \"\\n > a dog is barking in a small room during a thunderstorm with audible wind. \\n\\n\"\n",
    "        \n",
    "    prompt += preface + \" (gunshot, vehicle engine, siren, crash).\" + \"\\n > a car chase with gunfire and sirens where a vehicle crashes. \\n\\n\"\n",
    "    \n",
    "    prompt += preface + \" (waterfall, wind, sizzle, crackle).\" + \"\\n > a fire is cracking with something sizzling near a waterfall with wind. \\n\\n\"\n",
    "    \n",
    "    prompt += preface + \" (stream, cough, cat, Purr).\" + \"\\n > a cat purrs near a coughing person while a stream can be heard. \\n\\n\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    prompt += \"imagine a scene with all of these sounds existing together: \" + f\"({human_sample}). \\n >\"\n",
    "    outputs = client.prompt(prompt)\n",
    "    outputs = outputs[0].text[len(prompt) + 1:]\n",
    "    final_output = outputs.split(\"\\n\")[0]\n",
    "    return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7b0e157-f67e-4c12-b7cb-e11db672328f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' A family is walking in the park, the parents talking and the children petting a dog and a cat. The dog barking and the cat meowing as well as birds chirping in the background. '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = gen_caption([\"cat\", \"dog\", \"bark\", \"hiss\"], alpaca_client)\n",
    "final"
>>>>>>> 3bb861fc4a6d27faba64b02f686a7e22bfdcd682
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "id": "c51b5515-8983-476f-8310-1784e9d6185c",
=======
   "execution_count": 48,
   "id": "e1deb69c-2846-4ff0-a9ff-278601b6d2ed",
>>>>>>> 3bb861fc4a6d27faba64b02f686a7e22bfdcd682
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[{'generated_text': 'This is happening in a shop that sells leather goods and performs auto repair. \\n\\nThe sound of sanding is followed by the sound of a piece of equipment being use to lightly rub against something'}]\n"
=======
      "0.0023412704467773438\n"
>>>>>>> 3bb861fc4a6d27faba64b02f686a7e22bfdcd682
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "prompt = '''For each of the 3 line summarize the sounds into a single sentence: \n",
    "imagine a scene with all of these sounds existing together: (inside, small room).\n",
    " > This is happening inside a small room. \n",
    "\n",
    "imagine a scene with all of these sounds existing together: (dog, bark, howl, speech).\n",
    " > a dog barking and howling with a person speaking aswell. \n",
    "\n",
    "imagine a scene with all of these sounds existing together: (Sanding, and Rub). \n",
    " > '''\n",
    "\n",
    "ans = generate_text(prompt)\n",
    "print(ans)"
=======
    "of = open(\"test_file.txt\", 'a')\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for i in range(10000):\n",
    "    a = 100003232 / 123123\n",
    "    # of.write(f'{i}\\n')\n",
    "    # of.flush()\n",
    "    \n",
    "t1 = time.time()\n",
    "dt = t1-t0\n",
    "print(dt)"
>>>>>>> 3bb861fc4a6d27faba64b02f686a7e22bfdcd682
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "id": "914ebb71-7b73-4fc2-b11f-dabf6c81286d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 tokenizer = LlamaTokenizer.from_pretrained(<span style=\"color: #808000; text-decoration-color: #808000\">\"/output/path\"</span>)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>model = LlamaForCausalLM.from_pretrained(<span style=\"color: #808000; text-decoration-color: #808000\">\"/output/path\"</span>)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'LlamaTokenizer'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 tokenizer = LlamaTokenizer.from_pretrained(\u001b[33m\"\u001b[0m\u001b[33m/output/path\u001b[0m\u001b[33m\"\u001b[0m)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0mmodel = LlamaForCausalLM.from_pretrained(\u001b[33m\"\u001b[0m\u001b[33m/output/path\u001b[0m\u001b[33m\"\u001b[0m)                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'LlamaTokenizer'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# tokenizer = LlamaTokenizer.from_pretrained(\"/output/path\")\n",
    "# model = LlamaForCausalLM.from_pretrained(\"/output/path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50bbece-0bd8-4e29-ab9d-d86fa417ddc7",
   "metadata": {},
   "outputs": [],
   "source": []
=======
   "execution_count": 49,
   "id": "134e9bdf-2f3a-4c4c-8a54-88f1387c3caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.95549898167006\n"
     ]
    }
   ],
   "source": [
    "a = 0.07481646537780762\n",
    "b = 0.0023412704467773438\n",
    "\n",
    "print(a / b)"
   ]
>>>>>>> 3bb861fc4a6d27faba64b02f686a7e22bfdcd682
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "diffuse",
   "language": "python",
   "name": "diffuse"
=======
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
>>>>>>> 3bb861fc4a6d27faba64b02f686a7e22bfdcd682
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.10.10"
=======
   "version": "3.9.13"
>>>>>>> 3bb861fc4a6d27faba64b02f686a7e22bfdcd682
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
