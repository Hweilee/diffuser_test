<!--Copy 2023 허깅페이스 팀. 모든 권리 보유.

아파치 라이선스 버전 2.0("라이선스")에 따라 라이선스가 부여되며, 라이선스를 준수하는 경우를 제외하고는 이 파일을 사용할 수 없습니다.
라이선스. 라이선스 사본은 다음 주소에서 구할 수 있습니다.

http://www.apache.org/licenses/LICENSE-2.0

관련 법률에서 요구하거나 서면으로 동의하지 않는 한, 라이선스에 따라 배포되는 소프트웨어는 다음과 같이 배포됩니다.
명시적이든 묵시적이든 어떠한 종류의 보증이나 조건 없이 "있는 그대로" 배포됩니다. 라이선스를 참조하세요.
라이선스에 따른 권한 및 제한을 규율하는 특정 언어를 참조하십시오.
-->

# 언컨디션 이미지 생성

[[오픈 인 콜랩]]

언컨디션 이미지 생성은 비교적 간단한 작업입니다. 모델은 텍스트나 이미지와 같은 추가 컨텍스트 없이 학습된 훈련 데이터와 유사한 이미지만 생성합니다.

[디퓨전 파이프라인`]은 추론을 위해 미리 훈련된 디퓨전 시스템을 사용하는 가장 쉬운 방법입니다.

먼저 [`디퓨전 파이프라인`]의 인스턴스를 생성하고 다운로드할 파이프라인 체크포인트를 지정합니다.
허브의 🧨디퓨저 [체크포인트](https://huggingface.co/models?library=diffusers&sort=downloads) 중 하나를 사용할 수 있습니다(사용할 체크포인트는 나비 이미지를 생성합니다).

<팁>

💡 나만의 언컨디션 이미지 생성 모델을 훈련하고 싶으신가요? 트레이닝 [가이드](training/unconditional_training)를 참고하여 나만의 이미지를 생성하는 방법을 알아보세요.

</Tip>

이 가이드에서는 [DDPM](https://arxiv.org/abs/2006.11239)을 사용한 언컨디션 이미지 생성에 [`DiffusionPipeline`]을 사용합니다:

'''파이썬
>>> from diffusers import DiffusionPipeline

>>> generator = DiffusionPipeline.from_pretrained("anton-l/ddpm-butterflies-128")
```

[디퓨전 파이프라인`]은 모든 모델링, 토큰화, 스케줄링 구성 요소를 다운로드하고 캐시합니다. 
이 모델은 약 14억 개의 파라미터로 구성되어 있으므로 GPU에서 실행할 것을 강력히 권장합니다.
파이토치에서와 마찬가지로 생성기 객체를 GPU로 이동할 수 있습니다:

'''python
>>> generator.to("cuda")
```

이제 `generator`를 사용하여 이미지를 생성할 수 있습니다:

```python
>>> image = generator().images[0]
```

출력은 기본적으로 [`PIL.Image`](https://pillow.readthedocs.io/en/stable/reference/Image.html?highlight=image#the-image-class) 객체로 래핑됩니다.

호출하여 이미지를 저장할 수 있습니다:

```python
>>> image.save("generated_image.png")
```

아래 스페이스를 사용해 보고 추론 단계 매개변수를 자유롭게 사용해 이미지 품질에 어떤 영향을 미치는지 확인해 보세요!

<iframe
	src="https://stevhliu-ddpm-butterflies-128.hf.space"
	frameborder="0"
	width="850"
	height="500"
></iframe>


Translated with www.DeepL.com/Translator (free version)