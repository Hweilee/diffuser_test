<!--Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

[[open-in-colab]]

# ‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏â‡∏ö‡∏±‡∏ö‡∏¢‡πà‡∏≠

Diffusion models ‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î random Gaussian noise ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡πÄ‡∏•‡πá‡∏Å‡πÜ (‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤ timesteps) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á sample ‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à ‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏á ‡∏ã‡∏∂‡πà‡∏á‡πÑ‡∏î‡πâ‡∏ô‡∏≥‡πÑ‡∏õ‡∏™‡∏π‡πà‡∏Å‡∏≤‡∏£‡∏à‡∏∏‡∏î‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏≤‡∏Å‡πÉ‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ generative AI ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏≤‡∏à‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏´‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å Diffusion models ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏ö‡∏ô‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ï‡πà‡∏≤‡∏á‡πÜ üß® Diffusers ‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏à‡∏∏‡∏î‡∏°‡∏∏‡πà‡∏á‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á Diffusion modedls ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢‡∏î‡∏≤‡∏¢

‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏±‡∏Å‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏Å‡πá‡∏ï‡∏≤‡∏° ‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏â‡∏ö‡∏±‡∏ö‡∏¢‡πà‡∏≠‡∏ô‡∏µ‡πà‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô üß® Diffusers ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß ‡πÇ‡∏î‡∏¢‡∏°‡∏µ‡πÄ‡∏û‡∏µ‡∏¢‡∏á 3 ‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏ß‡∏£‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å
* [`DiffusionPipeline`] ‡πÄ‡∏õ‡πá‡∏ô high-level end-to-end class ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏à‡∏ô samples ‡∏à‡∏≤‡∏Å pretrained diffusion models ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô inference
* Pretrained [model](./api/models) architectures ‡πÅ‡∏•‡∏∞ modules ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á diffusion systems ‡∏ï‡πà‡∏≤‡∏á‡πÜ
* [Schedulers](./api/schedulers/overview) ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏±‡∏•‡∏Å‡∏≠‡∏£‡∏¥‡∏ó‡∏∂‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏¥‡∏° noise ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô inference

 
<Tip>

‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡∏ñ‡∏π‡∏Å‡∏¢‡πà‡∏≠‡∏°‡∏≤‡∏à‡∏≤‡∏Å üß® Diffusers [notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡πà‡πÑ‡∏î‡πâ ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö üß® Diffusers ‡∏•‡∏≠‡∏á‡πÄ‡∏ä‡πá‡∏Ñ notebook ‡∏î‡∏π‡∏™‡∏¥!

</Tip>

‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏° ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Å‡πà‡∏≠‡∏ô‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏•‡∏á‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á:

```py
# uncomment to install the necessary libraries in Colab
#!pip install --upgrade diffusers accelerate transformers
```

- [ü§ó Accelerate](https://huggingface.co/docs/accelerate/index) ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥ distributed computing
- [ü§ó Transformers](https://huggingface.co/docs/transformers/index) ‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡πÉ‡∏ô diffusion models ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏≠‡∏¢‡πà‡∏≤‡∏á [Stable Diffusion](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/overview).

## DiffusionPipeline

[`DiffusionPipeline`] ‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡∏á‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô pretrained diffusion system ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö inference ‡∏°‡∏±‡∏ô‡∏Ñ‡∏∑‡∏≠ end-to-end system ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢ model ‡πÅ‡∏•‡∏∞ scheduler ‡πÇ‡∏î‡∏¢‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ [`DiffusionPipeline`] ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡πÜ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà pipeline ‡∏ï‡πà‡∏≤‡∏á‡πÜ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ô‡∏≥‡πÑ‡∏õ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÑ‡∏î‡πâ ‡πÅ‡∏•‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡∏π‡∏ó‡∏µ‡πà [üß® Diffusers Summary](./api/pipelines/overview#diffusers-summary)

| **Task**                     | **Description**                                                                                              | **Pipeline**
|------------------------------|--------------------------------------------------------------------------------------------------------------|-----------------|
| Unconditional Image Generation          | generate an image from Gaussian noise | [unconditional_image_generation](./using-diffusers/unconditional_image_generation) |
| Text-Guided Image Generation | generate an image given a text prompt | [conditional_image_generation](./using-diffusers/conditional_image_generation) |
| Text-Guided Image-to-Image Translation     | adapt an image guided by a text prompt | [img2img](./using-diffusers/img2img) |
| Text-Guided Image-Inpainting          | fill the masked part of an image given the image, the mask and a text prompt | [inpaint](./using-diffusers/inpaint) |
| Text-Guided Depth-to-Image Translation | adapt parts of an image guided by a text prompt while preserving structure via depth estimation | [depth2img](./using-diffusers/depth2img) |

‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á instance ‡∏Ç‡∏≠‡∏á [`DiffusionPipeline`] ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏∏ checkpoint ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ [`DiffusionPipeline`] ‡∏Å‡∏±‡∏ö [checkpoint](https://huggingface.co/models?library=diffusers&sort=downloads) ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏ö‡∏ô Hugging Face Hub ‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ [`stable-diffusion-v1-5`](https://huggingface.co/runwayml/stable-diffusion-v1-5) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏à‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å text.

<Tip warning={true}>

‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö [Stable Diffusion](https://huggingface.co/CompVis/stable-diffusion) ‡∏Ñ‡∏ß‡∏£‡∏≠‡πà‡∏≤‡∏ô [license](https://huggingface.co/spaces/CompVis/stable-diffusion-license) ‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô üß® Diffusers ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô [`safety_checker`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/safety_checker.py) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏¥‡∏î‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ ‡πÅ‡∏ï‡πà‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á‡∏Å‡∏±‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å inference

</Tip>

‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ [`~DiffusionPipeline.from_pretrained`]:

```python
>>> from diffusers import DiffusionPipeline

>>> pipeline = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", use_safetensors=True)
```

[`DiffusionPipeline`] ‡∏à‡∏∞‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡πÇ‡∏°‡∏î‡∏π‡∏• modeling, tokenization, ‡πÅ‡∏•‡∏∞ scheduling ‡πÄ‡∏´‡πá‡∏ô‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤ Stable Diffusion pipeline ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢ [`UNet2DConditionModel`] ‡πÅ‡∏•‡∏∞ [`PNDMScheduler`] ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏≠‡∏∑‡πà‡∏ô‡πÜ:

```py
>>> pipeline
StableDiffusionPipeline {
  "_class_name": "StableDiffusionPipeline",
  "_diffusers_version": "0.13.1",
  ...,
  "scheduler": [
    "diffusers",
    "PNDMScheduler"
  ],
  ...,
  "unet": [
    "diffusers",
    "UNet2DConditionModel"
  ],
  "vae": [
    "diffusers",
    "AutoencoderKL"
  ]
}
```

‡πÄ‡∏£‡∏≤‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ô pipeline ‡∏ö‡∏ô GPU ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢ 1.4 ‡∏û‡∏±‡∏ô‡∏•‡πâ‡∏≤‡∏ô‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå
‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏¢‡πâ‡∏≤‡∏¢ generator object ‡πÑ‡∏õ‡∏≠‡∏¢‡∏π‡πà‡∏ö‡∏ô GPU ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏ï‡πà‡∏≤‡∏á‡πÜ‡πÉ‡∏ô PyTorch:

```python
>>> pipeline.to("cuda")
```

‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ô‡πâ‡∏±‡∏ô‡∏Å‡πá‡πÉ‡∏´‡πâ text prompt ‡∏Å‡∏±‡∏ö `pipeline` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡∏ü‡∏≠‡∏£‡πå‡πÅ‡∏°‡∏ï‡∏Ç‡∏≠‡∏á [`PIL.Image`](https://pillow.readthedocs.io/en/stable/reference/Image.html?highlight=image#the-image-class)

```python
>>> image = pipeline("An image of a squirrel in Picasso style").images[0]
>>> image
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/image_of_squirrel_painting.png"/>
</div>

‡πÄ‡∏ã‡∏ü‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏î‡πâ‡∏ß‡∏¢ `save`:

```python
>>> image.save("image_of_squirrel_painting.png")
```

### Local pipeline

‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏±‡∏ô pipeline ‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ã‡∏ü‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏î‡πâ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏•‡∏á‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà local storage

```bash
!git lfs install
!git clone https://huggingface.co/runwayml/stable-diffusion-v1-5
```

‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Ç‡πâ‡∏≤ pipeline

```python
>>> pipeline = DiffusionPipeline.from_pretrained("./stable-diffusion-v1-5", use_safetensors=True)
```

‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏±‡∏ô pipeline ‡πÑ‡∏î‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤

### ‡∏™‡∏•‡∏±‡∏ö schedulers

Schedulers ‡∏ï‡πà‡∏≤‡∏á‡πÜ‡∏°‡∏µ‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô‡πÅ‡∏•‡∏∞‡∏î‡πâ‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô ‡∏Å‡∏≤‡∏£‡∏™‡∏•‡∏±‡∏ö schedulers ‡πÉ‡∏ô üß® Diffusers ‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡πÑ‡∏°‡πà‡∏¢‡∏≤‡∏Å ‡πÄ‡∏ä‡πà‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏•‡∏±‡∏ö [`PNDMScheduler`] ‡πÄ‡∏õ‡πá‡∏ô [`EulerDiscreteScheduler`] ‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å [`~diffusers.ConfigMixin.from_config`]:

```py
>>> from diffusers import EulerDiscreteScheduler

>>> pipeline = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", use_safetensors=True)
>>> pipeline.scheduler = EulerDiscreteScheduler.from_config(pipeline.scheduler.config)
```

‡∏•‡∏≠‡∏á‡πÄ‡∏à‡∏ô‡∏£‡∏π‡∏õ‡∏î‡πâ‡∏ß‡∏¢ scheduler ‡πÉ‡∏´‡∏°‡πà‡∏î‡∏π‡πÅ‡∏•‡∏∞‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏™‡∏¥!

‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏°‡∏≤‡∏î‡∏π model ‡πÅ‡∏•‡∏∞ scheduler ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á [`DiffusionPipeline`] ‡πÅ‡∏•‡∏∞‡∏°‡∏≤‡∏î‡∏π‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏°‡∏±‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏à‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏ô‡πâ‡∏≠‡∏á‡πÅ‡∏°‡∏ß‡∏Å‡∏±‡∏ô

## Models

Models ‡∏™‡πà‡∏ß‡∏ô‡∏°‡∏≤‡∏Å‡∏à‡∏∞‡∏£‡∏±‡∏ö noisy sample ‡πÅ‡∏•‡∏∞‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ timestep ‡∏°‡∏±‡∏ô‡∏à‡∏∞‡∏Ñ‡∏≤‡∏î‡πÄ‡∏î‡∏≤ *noise residual* ‡∏ã‡∏µ‡πà‡∏á‡∏Ñ‡∏∑‡∏≠‡∏™‡πà‡∏ß‡∏ô‡∏ï‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡∏°‡∏µ noise ‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ sample ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô ‡∏ì timestep ‡∏ô‡∏±‡πâ‡∏ô‡πÜ (models ‡∏≠‡∏∑‡πà‡∏ô‡πÜ‡∏≠‡∏≤‡∏à‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏≤ latent image sample ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏≤‡∏à‡πÄ‡∏î‡∏≤ velocity ‡∏´‡∏£‡∏∑‡∏≠ [`v-prediction`](https://github.com/huggingface/diffusers/blob/5e5ce13e2f89ac45a0066cb3f369462a3cf1d9ef/src/diffusers/schedulers/scheduling_ddim.py#L110))

Models ‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏î‡πâ‡∏ß‡∏¢ [`~ModelMixin.from_pretrained`] ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å Huggingface Hub ‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà local storage ‡∏î‡πâ‡∏ß‡∏¢ ‡πÇ‡∏î‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ [`UNet2DModel`] ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô basic unconditional image generation model ‡∏î‡πâ‡∏ß‡∏¢ checkpoint ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÉ‡∏´‡πâ‡πÄ‡∏à‡∏ô‡∏£‡∏π‡∏õ‡∏ô‡πâ‡∏≠‡∏á‡πÅ‡∏°‡∏ß‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞:

```py
>>> from diffusers import UNet2DModel

>>> repo_id = "google/ddpm-cat-256"
>>> model = UNet2DModel.from_pretrained(repo_id, use_safetensors=True)
```

‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏£‡∏≤‡∏ö model parameters ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å `model.config`:

```py
>>> model.config
```

Model configuration ‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô üßä frozen üßä dictionary ‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á parameters ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏π‡∏Å‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏´‡∏•‡∏±‡∏á model ‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô ‡πÅ‡∏ï‡πà parameters ‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ô‡∏±‡πâ‡∏ô‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏î‡πâ ‡πÄ‡∏ä‡πà‡∏ô inference parameters

Model configuration parameters ‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏≠‡∏≤‡∏à‡∏°‡∏µ:

* `sample_size`: the height and width dimension of the input sample.
* `in_channels`: the number of input channels of the input sample.
* `down_block_types` and `up_block_types`: the type of down- and upsampling blocks used to create the UNet architecture.
* `block_out_channels`: the number of output channels of the downsampling blocks; also used in reverse order for the number of input channels of the upsampling blocks.
* `layers_per_block`: the number of ResNet blocks present in each UNet block.

‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô inference ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á random Gaussian noise ‡∏ó‡∏µ‡πà‡∏°‡∏µ dimensions ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö image shape ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‡πÇ‡∏î‡∏¢ tensor ‡πÄ‡∏õ‡πá‡∏ô 4 ‡∏°‡∏¥‡∏ï‡∏¥‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢ `batch` axis, `channel` axis, ‡πÅ‡∏•‡∏∞ `sample_size` axis (‡πÅ‡∏ï‡∏Å‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô `height` ‡πÅ‡∏•‡∏∞ `width` axis):

```py
>>> import torch

>>> torch.manual_seed(0)

>>> noisy_sample = torch.randn(1, model.config.in_channels, model.config.sample_size, model.config.sample_size)
>>> noisy_sample.shape
torch.Size([1, 3, 256, 256])
```

‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏≤ tensor ‡πÅ‡∏•‡∏∞ `timestep` ‡∏™‡πà‡∏á‡πÑ‡∏õ‡πÉ‡∏´‡πâ model ‡∏ã‡∏∂‡πà‡∏á `timestep` ‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ö‡∏≠‡∏Å‡∏ñ‡∏∂‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö noise ‡∏Ç‡∏≠‡∏á input image ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ model ‡∏£‡∏π‡πâ‡∏ñ‡∏∂‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö noise ‡πÅ‡∏•‡∏∞‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏°‡∏±‡∏ô‡πÉ‡∏ô SDE trajectory ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ó‡∏≥ diffusion ‡∏ß‡πà‡∏≤‡∏°‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏ä‡πâ `sample` ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á output ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•:

```py
>>> with torch.no_grad():
...     noisy_residual = model(sample=noisy_sample, timestep=2).sample
```

‡πÅ‡∏ï‡πà‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏à‡∏ô‡∏£‡∏π‡∏õ‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ scheduler ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÅ‡∏ï‡πà‡∏•‡∏∞ timesteps ‡πÅ‡∏•‡∏∞‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á noise ‡∏ó‡∏µ‡πà‡πÉ‡∏™‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô sample

## Schedulers

Schedulers ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° `noisy_residual` ‡∏ó‡∏µ‡πà‡∏ö‡∏≠‡∏Å‡∏ñ‡∏∂‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö noise ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ sample

<Tip>

üß® Diffusers ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö custom model ‡∏´‡∏£‡∏∑‡∏≠ custom schedulers ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏≠‡∏á‡πÑ‡∏î‡πâ ‡πÅ‡∏°‡πâ [`DiffusionPipeline`] ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô prebuilt pipelines ‡∏Å‡πá‡∏ï‡∏≤‡∏°

</Tip>

‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ [`DDPMScheduler`] ‡πÇ‡∏î‡∏¢‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏°‡∏±‡∏ô‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å [`~diffusers.ConfigMixin.from_config`]:

```py
>>> from diffusers import DDPMScheduler

>>> scheduler = DDPMScheduler.from_config(repo_id)
>>> scheduler
DDPMScheduler {
  "_class_name": "DDPMScheduler",
  "_diffusers_version": "0.13.1",
  "beta_end": 0.02,
  "beta_schedule": "linear",
  "beta_start": 0.0001,
  "clip_sample": true,
  "clip_sample_range": 1.0,
  "num_train_timesteps": 1000,
  "prediction_type": "epsilon",
  "trained_betas": null,
  "variance_type": "fixed_small"
}
```

<Tip>

üí° ‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏ß‡πà‡∏≤ scheduler ‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏à‡∏≤‡∏Å configuration ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å schedulers ‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ checkpoints ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡πÜ‡∏Ç‡∏≠‡∏á pipeline

</Tip>

Parameters ‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢:

* `num_train_timesteps`: the length of the denoising process or in other words, the number of timesteps required to process random Gaussian noise into a data sample.
* `beta_schedule`: the type of noise schedule to use for inference and training.
* `beta_start` and `beta_end`: the start and end noise values for the noise schedule.

‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏î‡πâ sample ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å [`~diffusers.DDPMScheduler.step`] ‡∏î‡πâ‡∏ß‡∏¢ `timestep` ‡πÅ‡∏•‡∏∞ `sample` ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô.

```py
>>> less_noisy_sample = scheduler.step(model_output=noisy_residual, timestep=2, sample=noisy_sample).prev_sample
>>> less_noisy_sample.shape
```

`less_noisy_sample` ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ô‡∏≥‡πÑ‡∏õ‡∏Ñ‡∏ß‡∏ö‡∏Å‡∏±‡∏ö `timestep` ‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏≤‡∏î‡πÄ‡∏î‡∏≤ noisy residual ‡πÅ‡∏•‡∏∞‡∏ß‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö ‡∏à‡∏ô‡πÑ‡∏î‡πâ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ noise ‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î 

‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏Ñ‡∏ß‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á function ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á `PIL.Image` ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ:

```py
>>> import PIL.Image
>>> import numpy as np


>>> def display_sample(sample, i):
...     image_processed = sample.cpu().permute(0, 2, 3, 1)
...     image_processed = (image_processed + 1.0) * 127.5
...     image_processed = image_processed.numpy().astype(np.uint8)

...     image_pil = PIL.Image.fromarray(image_processed[0])
...     display(f"Image at step {i}")
...     display(image_pil)
```

‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏¢‡πâ‡∏≤‡∏¢‡∏ó‡∏±‡πâ‡∏á input tensor ‡πÅ‡∏•‡∏∞ model ‡πÑ‡∏õ GPU:

```py
>>> model.to("cuda")
>>> noisy_sample = noisy_sample.to("cuda")
```

‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á denoising loop ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ model ‡πÄ‡∏î‡∏≤ residual ‡∏Ç‡∏≠‡∏á noisy sample ‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠‡πÉ‡∏´‡πâ scheduler ‡∏ô‡∏≥‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏õ‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏î‡πâ sample ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏£‡∏∞‡∏î‡∏±‡∏ö noise ‡∏•‡∏î‡∏•‡∏á:

```py
>>> import tqdm

>>> sample = noisy_sample

>>> for i, t in enumerate(tqdm.tqdm(scheduler.timesteps)):
...     # 1. predict noise residual
...     with torch.no_grad():
...         residual = model(sample, t).sample

...     # 2. compute less noisy image and set x_t -> x_t-1
...     sample = scheduler.step(residual, t, sample).prev_sample

...     # 3. optionally look at image
...     if (i + 1) % 50 == 0:
...         display_sample(sample, i + 1)
```

‡πÄ‡∏£‡∏≤‡∏°‡∏≤‡∏î‡∏π‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏±‡∏ô üòª

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/diffusion-quicktour.png"/>
</div>

## Next steps

‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏ñ‡∏±‡∏î‡πÜ‡πÑ‡∏õ ‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏≤‡∏à‡∏•‡∏≠‡∏á‡∏™‡∏¥‡πà‡∏á‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏î‡∏π:

* Train or finetune a model to generate your own images in the [training](./tutorials/basic_training) tutorial.
* See example official and community [training or finetuning scripts](https://github.com/huggingface/diffusers/tree/main/examples#-diffusers-examples) for a variety of use cases.
* Learn more about loading, accessing, changing and comparing schedulers in the [Using different Schedulers](./using-diffusers/schedulers) guide.
* Explore prompt engineering, speed and memory optimizations, and tips and tricks for generating higher quality images with the [Stable Diffusion](./stable_diffusion) guide.
* Dive deeper into speeding up üß® Diffusers with guides on [optimized PyTorch on a GPU](./optimization/fp16), and inference guides for running [Stable Diffusion on Apple Silicon (M1/M2)](./optimization/mps) and [ONNX Runtime](./optimization/onnx).
