name: Run all tests

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

env:
  HF_HOME: /mnt/cache
  OMP_NUM_THREADS: 8
  MKL_NUM_THREADS: 8
  PYTEST_TIMEOUT: 1000
  RUN_SLOW: yes
  PYTORCH: 1.12.1
  CUDA_CACHE_DISABLE: 0
  CUDA_CACHE_MAXSIZE: 34359738368  # 32GB
  CUDA_CACHE_PATH: /mnt/cuda_cache

jobs:
  run_tests_single_gpu:
    name: Diffusers tests
    strategy:
      fail-fast: false
      matrix:
        machine_type: [ single-gpu ]
    runs-on: [ self-hosted, docker-gpu, '${{ matrix.machine_type }}' ]
    container:
      image: nvidia/cuda:11.6.1-cudnn8-devel-ubuntu20.04
      options: --gpus 0 --shm-size "16gb" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/ -v /mnt/cuda_cache:/mnt/cuda_cache

    steps:
    - name: Checkout diffusers
      uses: actions/checkout@v3
      with:
        fetch-depth: 2

    - name: NVIDIA-SMI
      run: |
        nvidia-smi

    - name: Install dependencies
      run: |
        apt update
        apt install -y git git-lfs python3 python3-pip
        python3 -m pip install --upgrade pip
        python3 -m pip install torch=="$PYTORCH" torchvision --extra-index-url https://download.pytorch.org/whl/cu116
        python3 -m pip install -e .[quality,test]

    - name: Environment
      run: |
        python3 utils/print_env.py

    - name: Run all (incl. slow) tests on GPU
      env:
        HUGGING_FACE_HUB_TOKEN: ${{ secrets.HUGGING_FACE_HUB_TOKEN }}
      run: |
        python3 -m pytest -n 1 --max-worker-restart=0 --dist=loadfile -s -v --make-reports=tests_torch_gpu tests/

    - name: Failure short reports
      if: ${{ failure() }}
      run: cat reports/tests_torch_gpu_failures_short.txt

    - name: Test suite reports artifacts
      if: ${{ always() }}
      uses: actions/upload-artifact@v2
      with:
        name: torch_test_reports
        path: reports



  run_examples_single_gpu:
    name: Examples tests
    strategy:
      fail-fast: false
      matrix:
        machine_type: [ single-gpu ]
    runs-on: [ self-hosted, docker-gpu, '${{ matrix.machine_type }}' ]
    container:
      image: nvidia/cuda:11.6.1-cudnn8-devel-ubuntu20.04
      options: --gpus 0 --shm-size "16gb" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/ -v /mnt/cuda_cache:/mnt/cuda_cache

    steps:
    - name: Checkout diffusers
      uses: actions/checkout@v3
      with:
        fetch-depth: 2

    - name: NVIDIA-SMI
      run: |
        nvidia-smi

    - name: Install dependencies
      run: |
        apt update
        apt install -y git git-lfs python3 python3-pip
        python3 -m pip install --upgrade pip
        python3 -m pip install torch=="$PYTORCH" torchvision --extra-index-url https://download.pytorch.org/whl/cu116
        python3 -m pip install -e .[quality,test,training]

    - name: Environment
      run: |
        python3 utils/print_env.py

    - name: Run example tests on GPU
      env:
        HUGGING_FACE_HUB_TOKEN: ${{ secrets.HUGGING_FACE_HUB_TOKEN }}
      run: |
        python3 -m pytest -n 1 --max-worker-restart=0 --dist=loadfile -s -v --make-reports=examples_torch_gpu examples/

    - name: Failure short reports
      if: ${{ failure() }}
      run: cat reports/examples_torch_gpu_failures_short.txt

    - name: Test suite reports artifacts
      if: ${{ always() }}
      uses: actions/upload-artifact@v2
      with:
        name: examples_test_reports
        path: reports
