{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7GCm6p4QFVw"
      },
      "source": [
        "# **Verify that you're running in a capable GPU-enabled environment**\n",
        "\n",
        "Ensure that your environment is GPU-enabled and has at least 16GB RAM.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XU7NuMAA2drw",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Check type of GPU and VRAM available.\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYSGsQx75MqP"
      },
      "source": [
        "# **Restart runtime**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRCK4SHl5SbR",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Kill switch\n",
        "\n",
        "#@markdown If your GPU needs to be cleared, run this script to crash & restart the runtime.\n",
        "\n",
        "def kill():\n",
        "  from os import kill, getpid\n",
        "  kill(getpid(), 9) # This will crash Colab (run when runtime needs reset)\n",
        "\n",
        "kill()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnTMyW41cC1E"
      },
      "source": [
        "# **Initialize environment**\n",
        "\n",
        "In this section, you will setup your environment to run the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h27uU6wdXson"
      },
      "source": [
        "## **Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aLWXPZqjsZVV"
      },
      "outputs": [],
      "source": [
        "def changeDirectory(p):\n",
        "  from os import chdir\n",
        "  chdir(p)\n",
        "\n",
        "def createDirectory(p):\n",
        "    try:\n",
        "        from os import makedirs\n",
        "        makedirs(p)\n",
        "        print(f\"Directory '{p}' created\")\n",
        "    except OSError as e:\n",
        "        print(f\"Directory '{p}' already exists\")\n",
        "\n",
        "def mountGdriveIfNotMounted():\n",
        "    if not exists('/content/drive'):\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        print(\"Gdrive mounted\")\n",
        "\n",
        "def normalizePath(p, useGdrive=False):\n",
        "    from os import makedirs\n",
        "    if useGdrive:\n",
        "        mountGdriveIfNotMounted()\n",
        "        path = \"/content/drive/MyDrive/\" + p\n",
        "    else:\n",
        "        path = \"/content/\" + p\n",
        "    createDirectory(path);\n",
        "    return path;\n",
        "\n",
        "def sys(c, logOutput = False):\n",
        "    from subprocess import run, PIPE\n",
        "    p = run(c, shell=True, stdout=PIPE, stderr=PIPE)\n",
        "    output = p.stdout.decode()\n",
        "    errors = p.stderr.decode()\n",
        "    if logOutput :\n",
        "        print(output)\n",
        "    if errors != \"\" :\n",
        "        print(errors)\n",
        "\n",
        "def exists(p):\n",
        "    from os import path\n",
        "    return path.exists(p)\n",
        "\n",
        "def isEmpty(p):\n",
        "    from os import listdir\n",
        "    return len(listdir(p)) == 0\n",
        "\n",
        "def cloneRepo(server, name, destination):\n",
        "    changeDirectory(\"/content\")\n",
        "    repo = f\"{server}/{name}\"\n",
        "    command = f\"git clone https://{repo}.git\"\n",
        "    if destination != \"\":\n",
        "        sys(command  +\" \"+ destination)\n",
        "    else:\n",
        "        sys(command)\n",
        "    print(f\"Repo '{repo}' cloned to '{destination}'\")\n",
        "    changeDirectory(\"/content\")\n",
        "\n",
        "def updateRepo(server, name, destination):\n",
        "    changeDirectory(destination)\n",
        "    sys(\"git pull\")\n",
        "    print(f\"Repo {server}/{name} in directory {destination} updated\")\n",
        "    changeDirectory(\"/content\")\n",
        "\n",
        "def clearDirectory(destination):\n",
        "    sys(f\"rm -f -r {destination}\")\n",
        "    print(f\"Directory {destination} deleted\")\n",
        "    changeDirectory(\"/content\")\n",
        "\n",
        "def pipInstall(parameters):\n",
        "    sys(f\"pip install {parameters}\")\n",
        "    print(f\"'pip install' completed with parameters '{parameters}'\")\n",
        "\n",
        "#@markdown ### Repo\n",
        "\n",
        "#@markdown Which repo do you want to use\n",
        "\n",
        "REPO_SERVER = \"github.com\" #@param [\"github.com\"]\n",
        "\n",
        "REPO = \"jslegers/diffusers\" #@param [\"jslegers/diffusers\", \"ShivamShrirao/diffusers\", \"huggingface/diffusers\"]\n",
        "\n",
        "#@markdown Where to install\n",
        "\n",
        "INSTALL_REPO_ON_GDRIVE = True #@param {type:\"boolean\"}\n",
        "\n",
        "INSTALLATION_PATH = \"diffusers\" #@param {type:\"string\"}\n",
        "INSTALLATION_PATH = normalizePath(INSTALLATION_PATH, INSTALL_REPO_ON_GDRIVE)\n",
        "\n",
        "IF_DIRECTORY_NOT_EMPTY = \"Update\" #@param [\"Update\", \"Reinstall\", \"Do nothing\"]\n",
        "\n",
        "if exists(INSTALLATION_PATH) and not isEmpty(INSTALLATION_PATH):\n",
        "    if IF_DIRECTORY_NOT_EMPTY == \"Update\":\n",
        "        updateRepo(REPO_SERVER, REPO, INSTALLATION_PATH)\n",
        "    elif IF_DIRECTORY_NOT_EMPTY == \"Reinstall\":\n",
        "        clearDirectory(INSTALLATION_PATH)\n",
        "        cloneRepo(REPO_SERVER, REPO, INSTALLATION_PATH)\n",
        "else:\n",
        "    cloneRepo(REPO_SERVER, REPO, INSTALLATION_PATH)\n",
        "pipInstall(f\"git+file:{INSTALLATION_PATH}\")\n",
        "\n",
        "pipInstall(\"-q -U --pre triton\")\n",
        "pipInstall(\"-q accelerate==0.12.0 transformers ftfy bitsandbytes gradio\")\n",
        "\n",
        "#@markdown ### Wheels\n",
        "\n",
        "#@markdown Where compiled on Tesla T4, but should also work on P100, thanks to https://github.com/OMGhozlan\n",
        "\n",
        "#@markdown If precompiled wheels don't work, uncheck this flag.\n",
        "\n",
        "#@markdown If not using precompoled wheels, wheels will take around 40 minutes to compile.\n",
        "\n",
        "USE_PRECOMPILED_WHEELS = True #@param {type:\"boolean\"}\n",
        "\n",
        "if USE_PRECOMPILED_WHEELS:\n",
        "    pipInstall(\"-q https://github.com/OMGhozlan/xformers_colab/releases/download/1.0.0/xformers-0.0.15.dev0+cu11.2-cp38-cp38-linux_x86_64.whl\")\n",
        "else:\n",
        "    pipInstall(\"git+https://github.com/facebookresearch/xformers@1d31a3a#egg=xformers\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0NV324ZcL9L"
      },
      "source": [
        "## **Login to HF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "y4lqqWT_uxD2"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Login to HuggingFace\n",
        "\n",
        "#@markdown You need to accept the model license before downloading or using the Stable Diffusion weights.\n",
        "\n",
        "#@markdown Please, visit the [model card](https://huggingface.co/CompVis/stable-diffusion-v1-4), read the license and tick the checkbox if you agree. You have to be a registered user in Hugging Face Hub, and you'll also need to use an access token for the code to work.\n",
        "\n",
        "def sys(c, logOutput = False):\n",
        "    from subprocess import run, PIPE\n",
        "    p = run(c, shell=True, stdout=PIPE, stderr=PIPE)\n",
        "    output = p.stdout.decode()\n",
        "    errors = p.stderr.decode()\n",
        "    if logOutput :\n",
        "        print(output)\n",
        "    if errors != \"\" :\n",
        "        print(errors)\n",
        "\n",
        "def loginToHuggingFace():\n",
        "    from huggingface_hub import notebook_login\n",
        "    sys('git config --global credential.helper store')\n",
        "    notebook_login()\n",
        "\n",
        "loginToHuggingFace()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w148Ym4NdJk"
      },
      "source": [
        "## **Configuration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Rxg0y5MBudmd"
      },
      "outputs": [],
      "source": [
        "def exists(p):\n",
        "    from os import path\n",
        "    return path.exists(p)\n",
        "    \n",
        "def createDirectory(p):\n",
        "    try:\n",
        "        from os import makedirs\n",
        "        makedirs(p)\n",
        "        print(f\"Directory '{p}' created\")\n",
        "    except OSError as e:\n",
        "        print(f\"Directory '{p}' already exists\")\n",
        "\n",
        "def mountGdriveIfNotMounted():\n",
        "    if not exists('/content/drive'):\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        print(\"Gdrive mounted\")\n",
        "\n",
        "def normalizePath(p, useGdrive=False):\n",
        "    from os import makedirs\n",
        "    if useGdrive:\n",
        "        mountGdriveIfNotMounted()\n",
        "        path = \"/content/drive/MyDrive/\" + p\n",
        "    else:\n",
        "        path = \"/content/\" + p\n",
        "    createDirectory(path);\n",
        "    return path;\n",
        "\n",
        "#@markdown ### Name/Path of the initial model\n",
        "\n",
        "LOAD_FROM = \"Repo\" #@param [\"Repo\", \"GDrive\", \"Runtime\"]\n",
        "\n",
        "INITIAL_MODEL = \"johnslegers/stable-diffusion-v1-5\" #@param {type:\"string\"}\n",
        "\n",
        "PRETRAINED_VAE = \"stabilityai/sd-vae-ft-mse\" #@param {type:\"string\"}\n",
        "\n",
        "if INITIAL_MODEL:\n",
        "    if LOAD_FROM == \"GDrive\":\n",
        "        INITIAL_MODEL = normalizePath(INITIAL_MODEL, True)\n",
        "    elif LOAD_FROM == \"Runtime\":\n",
        "        INITIAL_MODEL = normalizePath(INITIAL_MODEL, False)\n",
        "\n",
        "#@markdown ### The identifier you want to use for the concept you'll be training\n",
        "#@markdown This should be a rare identifier, so the ID doesn't confuse it for something else\n",
        "\n",
        "CONCEPT = \"johnslegers\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### A general name for class \n",
        "\n",
        "#@markdown For example, use \"dog\" for dog images, \"man\" for images of a male human, etc.\n",
        "\n",
        "CLASS_NAME = \"man\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Path where you want to store class images\n",
        "\n",
        "LOAD_CLASS_IMAGES_FROM_GDRIVE = True #@param {type:\"boolean\"}\n",
        "\n",
        "ONLY_GENERATE_CLASS_IMAGES_IF_DIRECTORY_IS_EMPTY = True #@param {type:\"boolean\"}\n",
        "\n",
        "CLASS_DIR = \"stable_diffusion/trainingimages/class/man\" #@param {type:\"string\"}\n",
        "if CLASS_DIR:\n",
        "    CLASS_DIR = normalizePath(CLASS_DIR, LOAD_CLASS_IMAGES_FROM_GDRIVE)\n",
        "\n",
        "#@markdown ### Path for images of the concept for training\n",
        "\n",
        "LOAD_CONCEPT_IMAGES_FROM_GDRIVE = True #@param {type:\"boolean\"}\n",
        "\n",
        "INPUT_DIR = \"stable_diffusion/trainingimages/concept/johnslegers\" #@param {type:\"string\"}\n",
        "if INPUT_DIR:\n",
        "    INPUT_DIR = normalizePath(INPUT_DIR, LOAD_CONCEPT_IMAGES_FROM_GDRIVE)\n",
        "\n",
        "#@markdown ### Path where the trained model will be saved\n",
        "\n",
        "SAVE_CONCEPT_IMAGES_TO_GDRIVE = True #@param {type:\"boolean\"}\n",
        "\n",
        "OUTPUT_DIR = \"stable_diffusion/trainedmodel/johnslegers-1-5-0.16_1100\" #@param {type:\"string\"}\n",
        "if OUTPUT_DIR:\n",
        "    OUTPUT_DIR = normalizePath(OUTPUT_DIR, SAVE_CONCEPT_IMAGES_TO_GDRIVE)\n",
        "\n",
        "#@markdown ### If model weights should be saved as a concept on the Huggingface website\n",
        "#@markdown Once you save it you can use your concept by loading the model on any `from_pretrained` function\n",
        "\n",
        "SAVE_TO_HUGGINGFACE = False #@param {type:\"boolean\"}\n",
        "\n",
        "NAME_OF_YOUR_CONCEPT = \"js-man\" #@param {type:\"string\"}\n",
        "WHERE_TO_SAVE_YOUR_CONCEPT = \"privately_to_my_profile\" #@param [\"public_library\", \"privately_to_my_profile\"]\n",
        "\n",
        "#@markdown Leave `hf_token_write` blank if you logged in with a token with `write access` in the [Initial Setup](#scrollTo=KbzZ9xe6dWwf).\n",
        "\n",
        "#@markdown If not, [go to your tokens settings and create a write access token](https://huggingface.co/settings/tokens)\n",
        "\n",
        "HF_TOKEN_WRITE = \"\" #@param {type:\"string\"}\n",
        "\n",
        "print(f\"[*] Concept is '{CONCEPT}'\")\n",
        "print(f\"[*] Class name is '{CLASS_NAME}'\")\n",
        "print(f\"[*] Initial model will be loaded from '{INITIAL_MODEL}'\")\n",
        "print(f\"[*] Class images will be loaded from '{CLASS_DIR}'\")\n",
        "print(f\"[*] Concept images will be loaded from '{INPUT_DIR}'\")\n",
        "print(f\"[*] Trained model will be saved at '{OUTPUT_DIR}'\")\n",
        "if SAVE_TO_HUGGINGFACE :\n",
        "    print(f\"[*] Trained model will be also saved at Huggingface as '{NAME_OF_YOUR_CONCEPT}'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXv-OWTn2LrS"
      },
      "source": [
        "## **Advanced configuration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Vs732Wyh2D_q"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Prompt with identifier specifing the instance\n",
        "#@markdown If empty, the trainer will use the concept name \n",
        "\n",
        "INSTANCE_PROMPT = \"johnslegers\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Prompt with identifier specifing the class\n",
        "#@markdown If empty, the trainer will use the class name \n",
        "\n",
        "CLASS_PROMPT = \"man\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Flag to add prior perservation loss \n",
        "\n",
        "WITH_PRIOR_PRESERVATION = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### The weight of prior preservation loss\n",
        "\n",
        "PRIOR_LOSS_WEIGHT = 1.0 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ### Minimal class images for prior perversation loss\n",
        "#@markdown If not have enough images, additional images will be sampled with class_prompt\n",
        "\n",
        "NUM_CLASS_IMAGES = 800 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ### A seed for reproducible training\n",
        "\n",
        "SEED = -1 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ### The resolution for input images\n",
        "#@markdown All the images in the train/validation dataset will be resized to this\n",
        "\n",
        "RESOLUTION = 512 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ### Whether to center crop images before resizing to resolution\n",
        "\n",
        "CENTER_CROP = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### Batch size (per device) for the training dataloader\n",
        "\n",
        "TRAIN_BATCH_SIZE = 1 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ### Batch size (per device) for sampling images\n",
        "\n",
        "SAMPLE_BATCH_SIZE = 4 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ### Total number of training epochs to perform\n",
        "\n",
        "NUM_TRAIN_EPOCHS = 1 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ### Total number of training steps to perform\n",
        "#@markdown If provided, overrides `NUM_TRAIN_EPOCHS`\n",
        "\n",
        "MAX_TRAIN_STEPS = 1100 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ### Number of updates steps to accumulate before performing a backward/update pass\n",
        "\n",
        "GRADIENT_ACCUMULATION_STEPS = 1 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ### Whether or not to use gradient checkpointing\n",
        "#@markdown This saves memory at the expense of slower backward pass\n",
        "\n",
        "GRADIENT_CHECKPOINTING = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### Initial learning rate (after the potential warmup period) to use\n",
        "\n",
        "LEARNING_RATE = 1e-6 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ### Scale the learning rate by the number of GPUs, gradient accumulation steps, and batch size\n",
        "\n",
        "SCALE_LR = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### The scheduler type to use\n",
        "\n",
        "LR_SCHEDULER = \"linear\" #@param [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"]\n",
        "\n",
        "#@markdown ### Number of steps for the warmup in the lr scheduler\n",
        "\n",
        "LR_WARMUP_STEPS = 0 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ### Whether or not to use 8-bit Adam from bitsandbytes\n",
        "\n",
        "USE_8BIT_ADAM = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### The beta1 parameter for the Adam optimizer\n",
        "\n",
        "ADAM_BETA1 = 0.9 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ### The beta2 parameter for the Adam optimizer\n",
        "\n",
        "ADAM_BETA2 = 0.999 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ### Weight decay to use\n",
        "\n",
        "ADAM_WEIGHT_DECAY = 1e-2 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ### Epsilon value for the Adam optimizer\n",
        "\n",
        "ADAM_EPSILON = 1e-08 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ### Max gradient norm\n",
        "\n",
        "MAX_GRAD_NORM = 1.0 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ### Whether or not to push the model to the Hub\n",
        "\n",
        "PUSH_TO_HUB = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### Whether to use authorization token\n",
        "#@markdown Will use the token generated when running `huggingface-cli login`\n",
        "#@markdown necessary to use this script with private models\n",
        "\n",
        "USE_AUTH_TOKEN = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### The token to use to push to the Model Hub\n",
        "#@markdown If empty and `USE_AUTH_TOKEN` is `True`, `HUB_TOKEN` will be set to the token you used to log into this notebook with\n",
        "\n",
        "HUB_TOKEN = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### The name of the repository to keep in sync with the local `OUTPUT_DIR`\n",
        "\n",
        "HUB_MODEL_ID = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### [TensorBoard](https://www.tensorflow.org/tensorboard) log directory.\n",
        "#@markdown Defaults to *`OUTPUT_DIR`/runs/**CURRENT_DATETIME_HOSTNAME*** if empty\n",
        "\n",
        "LOGGING_DIR = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Whether to use mixed precision\n",
        "#@markdown Bf16 requires PyTorch >= 1.10 and an Nvidia Ampere GPU.\n",
        "\n",
        "MIXED_PRECISION = \"fp16\" #@param [\"no\", \"fp16\", \"bf16\"]\n",
        "\n",
        "#@markdown ### For distributed training\n",
        "\n",
        "LOCAL_RANK = 4 #@param {type:\"integer\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ioxxvHoicPs"
      },
      "source": [
        "# **Start training**\n",
        "\n",
        "remove `--use_8bit_adam` flag in the cell below if you got more than equal to 18 GB VRAM.\n",
        "\n",
        "`--mixed_precision=\"fp16\"` uses a little more VRAM for some reason but is 1.5-2x faster on GPUs with tensor cores, change it to `--mixed_precision=\"no\"` if you face out of memory issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jjcSXTp-u-Eg"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Run script\n",
        "#@markdown This will run the training script with the configuration you defined\n",
        "\n",
        "COMMAND = f'''train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path={INITIAL_MODEL} \\\n",
        "{\"\" if not PRETRAINED_VAE else \"--pretrained_vae_name_or_path='\"+PRETRAINED_VAE + \"' \"}\\\n",
        "  --instance_data_dir=\"{INPUT_DIR}\" \\\n",
        "  --class_data_dir=\"{CLASS_DIR}\" \\\n",
        "  --instance_prompt=\"{INSTANCE_PROMPT or CONCEPT}\" \\\n",
        "  --class_prompt=\"{CLASS_PROMPT or CLASS_NAME}\" \\\n",
        "{\"\" if not WITH_PRIOR_PRESERVATION else \"--with_prior_preservation \"}\\\n",
        "  --prior_loss_weight={PRIOR_LOSS_WEIGHT} \\\n",
        "{\"\" if SEED == -1 else \"--seed=\"+SEED + \" \"}\\\n",
        "  --num_class_images={NUM_CLASS_IMAGES} \\\n",
        "  --output_dir=\"{OUTPUT_DIR}\" \\\n",
        "  --resolution={RESOLUTION} \\\n",
        "{\"\" if not CENTER_CROP else \"--center_crop \"}\\\n",
        "  --train_batch_size={TRAIN_BATCH_SIZE} \\\n",
        "  --sample_batch_size={SAMPLE_BATCH_SIZE} \\\n",
        "  --num_train_epochs={NUM_TRAIN_EPOCHS} \\\n",
        "  --max_train_steps={MAX_TRAIN_STEPS} \\\n",
        "  --gradient_accumulation_steps={GRADIENT_ACCUMULATION_STEPS} \\\n",
        "{\"\" if not GRADIENT_CHECKPOINTING else \"--gradient_checkpointing \"}\\\n",
        "  --learning_rate={LEARNING_RATE} \\\n",
        "{\"\" if not SCALE_LR else \"--scale_lr=\"+SCALE_LR + \" \"}\\\n",
        "  --lr_scheduler=\"{LR_SCHEDULER}\" \\\n",
        "  --lr_warmup_steps={LR_WARMUP_STEPS} \\\n",
        "{\"\" if not USE_8BIT_ADAM else \"--use_8bit_adam \"}\\\n",
        "  --adam_beta1={ADAM_BETA1} \\\n",
        "  --adam_beta2={ADAM_BETA2} \\\n",
        "  --adam_weight_decay={ADAM_WEIGHT_DECAY} \\\n",
        "  --adam_epsilon={ADAM_EPSILON} \\\n",
        "  --max_grad_norm={MAX_GRAD_NORM} \\\n",
        "{\"\" if not PUSH_TO_HUB else \"--push_to_hub \"}\\\n",
        "  --hub_model_id=\"{HUB_MODEL_ID}\" \\\n",
        "  --logging_dir=\"{\"logs\" if LOGGING_DIR == \"\" else LOGGING_DIR}\" \\\n",
        "  --mixed_precision=\"{MIXED_PRECISION}\" \\\n",
        "  --local_rank={LOCAL_RANK} \\\n",
        "  --train_text_encoder\n",
        "'''\n",
        "\n",
        "print(f\"Command launched = '{COMMAND}'\")\n",
        "\n",
        "%cd {INSTALLATION_PATH}/examples/dreambooth\n",
        "!accelerate launch $COMMAND"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phB77bWPgKFW"
      },
      "source": [
        "# Test the trained model\n",
        "\n",
        "Below you can test the model you just trained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToNG4fd_dTbF"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gW15FjffdTID",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Load your model\n",
        "\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from torch import float16, Generator\n",
        "\n",
        "if OUTPUT_DIR :\n",
        "    model_path = OUTPUT_DIR\n",
        "else:\n",
        "    model_path = INITIAL_MODEL\n",
        "\n",
        "print(f\"Loading model from {model_path}\")\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    model_path, \n",
        "    use_auth_token=True, \n",
        "    torch_dtype=float16,\n",
        "    safety_checker=None\n",
        ").to(\"cuda\")\n",
        "\n",
        "g_cuda = Generator(device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LImFd-BN25Sh",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Run your model\n",
        "\n",
        "from torch import autocast, inference_mode\n",
        "from IPython.display import display\n",
        "\n",
        "#@markdown Can set random seed here for reproducibility.\n",
        "seed = 742598945 #@param {type:\"integer\"}\n",
        "if(seed and seed > 0):\n",
        "    g_cuda.manual_seed(seed)\n",
        "else:\n",
        "    import random\n",
        "    seed = random.randint(0,4294967295)\n",
        "    g_cuda.manual_seed(seed)\n",
        "\n",
        "#@title Run for generating images.\n",
        "\n",
        "prompt = \"detailed portrait of johnslegers, unreal engine, octane render\" #@param {type:\"string\"}\n",
        "num_samples = 8 #@param {type:\"integer\"}\n",
        "guidance_scale = 7.5 #@param {type:\"number\"}\n",
        "num_inference_steps = 20 #@param {type:\"integer\"}\n",
        "height = 512 #@param {type:\"integer\"}\n",
        "width = 512 #@param {type:\"integer\"}\n",
        "\n",
        "print(\"Seed used: \" + str(seed))\n",
        "with autocast(\"cuda\"), inference_mode():\n",
        "    images = pipe([prompt] * num_samples, height=height, width=width, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale, generator=g_cuda).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WMCqQ5Tcdsm2"
      },
      "outputs": [],
      "source": [
        "#@markdown Run Gradio UI for generating images.\n",
        "from torch import autocast, inference_mode\n",
        "import gradio as gr\n",
        "\n",
        "model_path = OUTPUT_DIR #If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_path, torch_dtype=float16).to(\"cuda\")\n",
        "\n",
        "def inference(prompt, num_samples, height=512, width=512, num_inference_steps=50, guidance_scale=7.5):\n",
        "    with autocast(\"cuda\"), inference_mode():\n",
        "        return pipe(\n",
        "            [prompt]*int(num_samples), height=int(height), width=int(width),\n",
        "            num_inference_steps=int(num_inference_steps), guidance_scale=guidance_scale,\n",
        "            generator=g_cuda\n",
        "            ).images\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            prompt = gr.Textbox(label=\"Prompt\", value=\"photo of johnslegers man, digital painting\")\n",
        "            run = gr.Button(value=\"Generate\")\n",
        "            with gr.Row():\n",
        "                num_samples = gr.Number(label=\"Number of Samples\", value=4)\n",
        "                guidance_scale = gr.Number(label=\"Guidance Scale\", value=7.5)\n",
        "            with gr.Row():\n",
        "                height = gr.Number(label=\"Height\", value=512)\n",
        "                width = gr.Number(label=\"Width\", value=512)\n",
        "            num_inference_steps = gr.Slider(label=\"Steps\", value=50)\n",
        "        with gr.Column():\n",
        "            gallery = gr.Gallery()\n",
        "\n",
        "    run.click(inference, inputs=[prompt, num_samples, height, width, num_inference_steps, guidance_scale], outputs=gallery)\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 ('pytorch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}