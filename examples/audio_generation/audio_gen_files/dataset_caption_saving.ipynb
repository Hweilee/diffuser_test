{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd6efb4f-383c-49a0-8f3e-16f4b2deabc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import random\n",
    "import llm_client\n",
    "from AudiosetDataset import AudiosetDataset\n",
    "import torch\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# print(os.chdir(\"/home/junchenl/diffusers_with_dataloader/examples/text_to_image/audio_gen_files\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a69c44d-15f5-479d-a1a0-60209843f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "local = \"/home/junchenl/AudioTaggingDoneRight/egs/audioset/data\"\n",
    "label_csv=os.path.join(local, 'class_labels_indices.csv')\n",
    "data_path = os.path.join(local,'datafiles/audioset_bal_unbal_train_data.json')\n",
    "\n",
    "alpaca_client = llm_client.Client(address=\"tir-1-7\")\n",
    "llama_client  = llm_client.Client(address=\"tir-0-15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59436a03-56f2-433d-97c8-0dc9a86b061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = open(data_path)\n",
    "\n",
    "data = json.load(data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dbac8749-a995-41be-af4b-b0ab8a1a7d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {}\n",
    "with open(label_csv,'r') as data_file:\n",
    "    for line in csv.reader(data_file):\n",
    "        label_dict[line[1]] = line[2]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91b3754e-4170-423f-8b9f-eb28613c7980",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_caption(classes, client):\n",
    "    human_sample = \", \".join(classes[:-2] + [\", and \".join(classes[-2:])])\n",
    "    prompt = \"\"\n",
    "    prompt += \"For each of the 3 line summarize the sounds into a single sentence: \\n\"\n",
    "    prompt += \"imagine a scene with all of these sounds existing together: (inside, small room).\" + \"\\n > This is happening inside a small room. \\n\\n\"\n",
    "    prompt += \"imagine a scene with all of these sounds existing together: (dog, bark, howl, speech).\" + \"\\n > a dog barking and howling with a person speaking aswell. \\n\\n\"\n",
    "    prompt += \"imagine a scene with all of these sounds existing together: \" + f\"({human_sample}). \\n >\"\n",
    "    outputs = client.prompt(prompt)\n",
    "    outputs = outputs[0].text[len(prompt) + 1:]\n",
    "    final_output = outputs.split(\"\\n\")[0]\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f580c29-8814-4876-b9d9-7a1d55cf3078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f173ea11-872f-42b4-86d2-979efa009dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running list\n"
     ]
    },
    {
     "ename": "ServerError",
     "evalue": "Server-side Error -- RuntimeError: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServerError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4588/1793313710.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mlist_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpaca_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mpost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/tir6/strubell/billyli/lti-llm-deployment/llm_client/__init__.py\u001b[0m in \u001b[0;36mprompt\u001b[0;34m(self, text, max_new_tokens, output_scores, output_hidden_states, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             raise ServerError(\n\u001b[0m\u001b[1;32m     75\u001b[0m                 \u001b[0;34mf\"Server-side Error -- {response['error']}: {response['message']}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             )\n",
      "\u001b[0;31mServerError\u001b[0m: Server-side Error -- RuntimeError: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "dataset = [\n",
    "    \"here is a cookie recipe: \",\n",
    "    \"here is a brownie recipe: \",\n",
    "    \"here is a sandiwch recipe: \",\n",
    "    \"here is a cookie cake recipe: \"\n",
    "]\n",
    "print(\"running list\")\n",
    "pre = time.time()\n",
    "for _ in range(5):\n",
    "    list_gen = alpaca_client.prompt(dataset)\n",
    "post = time.time()\n",
    "\n",
    "list_dt = post - pre\n",
    "\n",
    "print(\"running ind\")\n",
    "pre = time.time()\n",
    "ind_gen = [0,0,0,0,0,0,0,0]\n",
    "for _ in range(5):\n",
    "    for i in range(4):\n",
    "        ind_gen[i] = alpaca_client.prompt(dataset[i])\n",
    "post = time.time()\n",
    "\n",
    "ind_dt = post - pre\n",
    "\n",
    "\n",
    "print(\"running comp\")\n",
    "pre = time.time()\n",
    "for _ in range(5):\n",
    "    comp_gen = [alpaca_client.prompt(p) for p in dataset]\n",
    "post = time.time()\n",
    "\n",
    "comp_dt = post - pre\n",
    "\n",
    "\n",
    "print(\"LIST: \", list_dt)\n",
    "print(\"INDEX: \", ind_dt)\n",
    "print(\"COMP: \", comp_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf09e968-9ec6-4bb9-8e3d-93bfeb988e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = alpaca_client.prompt([\"here is a cookie recipe: \", \"here is a sandwich recipe: \"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c204cff2-8ad3-433e-b483-d4d6eea04547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Output(text=' here is a cookie recipe: 1 cup of butter, 2 cups of sugar, 3 eggs, 1 teaspoon of vanilla extract, 1 and 1/4 cups of all-purpose flour, 1 teaspoon of salt, 1 cup of chocolate chips,', scores=None, hidden_states=None),\n",
       " Output(text=' here is a sandwich recipe: 1 slice whole wheat bread, 2 slices roast beef, 2 slices melted cheddar cheese, 1 tomato slice, 1 leaf of lettuce, 1 tbsp of horseradish sauce, and 1 tbsp of wasabi', scores=None, hidden_states=None)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5cea9c58-9074-4786-b34c-f6c272bc0147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                        | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 1\n",
      "0 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████████████                                                                                    | 1/4 [00:01<00:03,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3\n",
      "3 4\n",
      "3 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████████████████                                                        | 2/4 [00:02<00:02,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6\n",
      "6 7\n",
      "6 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████████████████████████████████                            | 3/4 [00:02<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9\n",
      "9 10\n",
      "9 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "# for i in tqdm(range(len(data[\"data\"]))):\n",
    "\n",
    "batch_size = 3\n",
    "\n",
    "for i in tqdm(range(0, 12, batch_size)):\n",
    "    for j in range(i, i + batch_size):\n",
    "        print(i,j)\n",
    "    datum = data[\"data\"][i]\n",
    "    labels = datum['labels'].split(\",\")\n",
    "    labels = [label_dict[label] for label in labels]\n",
    "    \n",
    "    cap = gen_caption(labels, alpaca_client)\n",
    "    \n",
    "    datum[\"caption\"] = cap\n",
    "    datum[\"classes\"] = labels\n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117d7c29-5f59-4570-b719-29ee95502add",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(local,'datafiles/alpaca_audioset_bal_unbal_train_data.json')\n",
    "\n",
    "out_file = open(output_path, \"w\")\n",
    "json.dump({\"data\": data[\"data\"]}, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "12bce86c-a5b0-407e-93bb-4332be50b209",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = open(\"ids_with_captions.json\", \"r\")\n",
    "\n",
    "\n",
    "test_data = json.load(test_file)[\"data\"]\n",
    "\n",
    "print(os.chdir(\"/home/junchenl/diffusers_with_dataloader/examples/text_to_image/audio_gen_files\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4130612f-3f4d-4253-af23-329047686760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Vehicle, Vehicle horn, car horn, honking, Speech', 'Music, Chatter, Speech, Inside, small room', 'Domestic animals, pets, Speech, Dog, Animal, Outside, rural or natural']\n"
     ]
    }
   ],
   "source": [
    "top = len(test_data)\n",
    "n_samples = 3\n",
    "\n",
    "rand_ids = [random.randint(0, top) for _ in range(n_samples)]\n",
    "\n",
    "name_list = list(test_data.keys())\n",
    "\n",
    "sample = [test_data[name_list[idx]] for idx in rand_ids]\n",
    "ids = [name_list[idx] for idx in rand_ids]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "09969c67-6517-4df1-9de5-58a8e978dfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:  N-J89jHemZg\n",
      "PROMPT:  imagine a scene with all of these sounds existing together: Vehicle, Vehicle horn, car horn, honking, and Speech. Then describe this scene in one sentence. \n",
      "\n",
      " imagine a scene with all of these sounds existing together: Vehicle, Vehicle horn, car horn, honking, and Speech. Then describe this scene in one sentence. In one minute describe the situation where all of these sounds co-exist.\n",
      "Bike and car with all types of people around it, pedestrians waiting to cross on street light.\n",
      "A horn from an angry driver who cannot get out of the carpark due to the traffic on the roads. (A\n",
      "=================================================\n",
      "ID:  _MJn4VJUPwE\n",
      "PROMPT:  imagine a scene with all of these sounds existing together: Music, Chatter, Speech, Inside, and small room. Then describe this scene in one sentence. \n",
      "\n",
      " imagine a scene with all of these sounds existing together: Music, Chatter, Speech, Inside, and small room. Then describe this scene in one sentence.\n",
      "This exercise and others like it can help you get your mind ready for the first step to writing a story: brainstorming.\n",
      "There are lots of ways to get ideas for a narrative; however, you usually need to experiment with several before you find the most effective for you. You may have to\n",
      "=================================================\n",
      "ID:  JWgNa4M67JY\n",
      "PROMPT:  imagine a scene with all of these sounds existing together: Domestic animals, pets, Speech, Dog, Animal, Outside, and rural or natural. Then describe this scene in one sentence. \n",
      "\n",
      " imagine a scene with all of these sounds existing together: Domestic animals, pets, Speech, Dog, Animal, Outside, and rural or natural. Then describe this scene in one sentence.\n",
      "This entry was posted in Uncategorized and tagged dogs in the background, Improvise, out in the field. Bookmark the permalink.\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for sam, idx in zip(sample, ids):\n",
    "    ls_sam  = sam.split(\", \")\n",
    "    human_sample = \", \".join(ls_sam[:-2] + [\", and \".join(ls_sam[-2:])])\n",
    "\n",
    "    prompt = \"imagine a scene with all of these sounds existing together: \" + human_sample + \". Then describe this scene in one sentence.\"\n",
    "    print(\"ID: \", idx)\n",
    "    print(\"PROMPT: \", prompt, \"\\n\") \n",
    "    outputs = llama_client.prompt(prompt)\n",
    "    # outputs = alpaca_client.prompt(prompt)\n",
    "    print(outputs[0].text)\n",
    "    print(\"=================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558205da-3204-46a9-8876-849b5a3e8439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
