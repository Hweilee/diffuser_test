{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81c71813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import RDMPipeline, StableDiffusionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0810a083",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e96a1bdfc7849b4b711e095231e67e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/543 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\fewshot_diffusion\\lib\\site-packages\\huggingface_hub\\file_download.py:127: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in D:\\cache\\huggingface\\diffusers. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d39fa767dd4f2696cde6832308e958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a4ef69020e4337bb508334405f6593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/342 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ad0224d6f0482cb105c9986cbd608d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33bd7efe0bf49e48f1693061867aa70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a946a9b8c8d4e7087df28a041ccec3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/209 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a050ab198f34462873a012c09907520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/592 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed23e16108984f18bc1f210ab0d5cd59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/492M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1176883ba7dd48f8b691d5186d251ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78377d8e27e74eed9cc1952550e40a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/472 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442f867a84e34c44baf7ca7daf2b621f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/806 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd54cd3f035649a29a7e766acfe736e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_dict\n",
      "{'scheduler': ['diffusers', 'PNDMScheduler'], 'feature_extractor': ['transformers', 'CLIPFeatureExtractor'], 'text_encoder': ['transformers', 'CLIPTextModel'], 'tokenizer': ['transformers', 'CLIPTokenizer'], 'safety_checker': ['stable_diffusion', 'StableDiffusionSafetyChecker'], 'unet': ['diffusers', 'UNet2DConditionModel'], 'vae': ['diffusers', 'AutoencoderKL']}\n",
      "name root: scheduler\n",
      "library_name: diffusers\n",
      "class_name: PNDMScheduler\n",
      "class_obj: <class 'diffusers.schedulers.scheduling_pndm.PNDMScheduler'>\n",
      "importable_classes: {'ModelMixin': ['save_pretrained', 'from_pretrained'], 'SchedulerMixin': ['save_config', 'from_config'], 'DiffusionPipeline': ['save_pretrained', 'from_pretrained'], 'OnnxRuntimeModel': ['save_pretrained', 'from_pretrained']}\n",
      "class_candidates: {'ModelMixin': <class 'diffusers.modeling_utils.ModelMixin'>, 'SchedulerMixin': <class 'diffusers.schedulers.scheduling_utils.SchedulerMixin'>, 'DiffusionPipeline': <class 'diffusers.pipeline_utils.DiffusionPipeline'>, 'OnnxRuntimeModel': <class 'diffusers.onnx_utils.OnnxRuntimeModel'>}\n",
      "<class 'diffusers.schedulers.scheduling_pndm.PNDMScheduler'>\n",
      "name root: feature_extractor\n",
      "library_name: transformers\n",
      "class_name: CLIPFeatureExtractor\n",
      "class_obj: <class 'transformers.models.clip.image_processing_clip.CLIPImageProcessor'>\n",
      "importable_classes: {'PreTrainedTokenizer': ['save_pretrained', 'from_pretrained'], 'PreTrainedTokenizerFast': ['save_pretrained', 'from_pretrained'], 'PreTrainedModel': ['save_pretrained', 'from_pretrained'], 'FeatureExtractionMixin': ['save_pretrained', 'from_pretrained']}\n",
      "class_candidates: {'PreTrainedTokenizer': <class 'transformers.tokenization_utils.PreTrainedTokenizer'>, 'PreTrainedTokenizerFast': <class 'transformers.tokenization_utils_fast.PreTrainedTokenizerFast'>, 'PreTrainedModel': <class 'transformers.modeling_utils.PreTrainedModel'>, 'FeatureExtractionMixin': <class 'transformers.feature_extraction_utils.FeatureExtractionMixin'>}\n",
      "<class 'transformers.models.clip.image_processing_clip.CLIPImageProcessor'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The component <class 'transformers.models.clip.image_processing_clip.CLIPImageProcessor'> of <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> cannot be loaded as it does not seem to have any of the loading methods defined in {'ModelMixin': ['save_pretrained', 'from_pretrained'], 'SchedulerMixin': ['save_config', 'from_config'], 'DiffusionPipeline': ['save_pretrained', 'from_pretrained'], 'OnnxRuntimeModel': ['save_pretrained', 'from_pretrained'], 'PreTrainedTokenizer': ['save_pretrained', 'from_pretrained'], 'PreTrainedTokenizerFast': ['save_pretrained', 'from_pretrained'], 'PreTrainedModel': ['save_pretrained', 'from_pretrained'], 'FeatureExtractionMixin': ['save_pretrained', 'from_pretrained']}.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mStableDiffusionPipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCompVis/stable-diffusion-v1-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\personal_projects\\chi_painting_generator\\diffusers\\src\\diffusers\\pipeline_utils.py:606\u001b[0m, in \u001b[0;36mDiffusionPipeline.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m none_module\u001b[38;5;241m.\u001b[39mstartswith(DUMMY_MODULES_FOLDER) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdummy\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m none_module:\n\u001b[0;32m    603\u001b[0m         \u001b[38;5;66;03m# call class_obj for nice error message of missing requirements\u001b[39;00m\n\u001b[0;32m    604\u001b[0m         class_obj()\n\u001b[1;32m--> 606\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    607\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe component \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_obj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be loaded as it does not seem to have\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    608\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m any of the loading methods defined in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mALL_IMPORTABLE_CLASSES\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    609\u001b[0m     )\n\u001b[0;32m    611\u001b[0m load_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(class_obj, load_method_name)\n\u001b[0;32m    612\u001b[0m loading_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31mValueError\u001b[0m: The component <class 'transformers.models.clip.image_processing_clip.CLIPImageProcessor'> of <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> cannot be loaded as it does not seem to have any of the loading methods defined in {'ModelMixin': ['save_pretrained', 'from_pretrained'], 'SchedulerMixin': ['save_config', 'from_config'], 'DiffusionPipeline': ['save_pretrained', 'from_pretrained'], 'OnnxRuntimeModel': ['save_pretrained', 'from_pretrained'], 'PreTrainedTokenizer': ['save_pretrained', 'from_pretrained'], 'PreTrainedTokenizerFast': ['save_pretrained', 'from_pretrained'], 'PreTrainedModel': ['save_pretrained', 'from_pretrained'], 'FeatureExtractionMixin': ['save_pretrained', 'from_pretrained']}."
     ]
    }
   ],
   "source": [
    "pipeline = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4511142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f8133ef8c4444dad7f9b86b38032fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_dict\n",
      "{'scheduler': ['diffusers', 'DDIMScheduler'], 'feature_extractor': ['transformers', 'CLIPFeatureExtractor'], 'tokenizer': ['transformers', 'CLIPTokenizer'], 'unet': ['diffusers', 'UNet2DConditionModel'], 'clip': ['transformers', 'CLIPModel'], 'vae': ['diffusers', 'AutoencoderKL']}\n",
      "name root: scheduler\n",
      "library_name: diffusers\n",
      "class_name: DDIMScheduler\n",
      "class_obj: <class 'diffusers.schedulers.scheduling_ddim.DDIMScheduler'>\n",
      "importable_classes: {'ModelMixin': ['save_pretrained', 'from_pretrained'], 'SchedulerMixin': ['save_config', 'from_config'], 'DiffusionPipeline': ['save_pretrained', 'from_pretrained'], 'OnnxRuntimeModel': ['save_pretrained', 'from_pretrained']}\n",
      "class_candidates: {'ModelMixin': <class 'diffusers.modeling_utils.ModelMixin'>, 'SchedulerMixin': <class 'diffusers.schedulers.scheduling_utils.SchedulerMixin'>, 'DiffusionPipeline': <class 'diffusers.pipeline_utils.DiffusionPipeline'>, 'OnnxRuntimeModel': <class 'diffusers.onnx_utils.OnnxRuntimeModel'>}\n",
      "<class 'diffusers.schedulers.scheduling_ddim.DDIMScheduler'>\n",
      "name root: feature_extractor\n",
      "library_name: transformers\n",
      "class_name: CLIPFeatureExtractor\n",
      "class_obj: <class 'transformers.models.clip.image_processing_clip.CLIPImageProcessor'>\n",
      "importable_classes: {'PreTrainedTokenizer': ['save_pretrained', 'from_pretrained'], 'PreTrainedTokenizerFast': ['save_pretrained', 'from_pretrained'], 'PreTrainedModel': ['save_pretrained', 'from_pretrained'], 'FeatureExtractionMixin': ['save_pretrained', 'from_pretrained']}\n",
      "class_candidates: {'PreTrainedTokenizer': <class 'transformers.tokenization_utils.PreTrainedTokenizer'>, 'PreTrainedTokenizerFast': <class 'transformers.tokenization_utils_fast.PreTrainedTokenizerFast'>, 'PreTrainedModel': <class 'transformers.modeling_utils.PreTrainedModel'>, 'FeatureExtractionMixin': <class 'transformers.feature_extraction_utils.FeatureExtractionMixin'>}\n",
      "<class 'transformers.models.clip.image_processing_clip.CLIPImageProcessor'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The component <class 'transformers.models.clip.image_processing_clip.CLIPImageProcessor'> of <class 'diffusers.pipelines.rdm.pipeline_rdm.RDMPipeline'> cannot be loaded as it does not seem to have any of the loading methods defined in {'ModelMixin': ['save_pretrained', 'from_pretrained'], 'SchedulerMixin': ['save_config', 'from_config'], 'DiffusionPipeline': ['save_pretrained', 'from_pretrained'], 'OnnxRuntimeModel': ['save_pretrained', 'from_pretrained'], 'PreTrainedTokenizer': ['save_pretrained', 'from_pretrained'], 'PreTrainedTokenizerFast': ['save_pretrained', 'from_pretrained'], 'PreTrainedModel': ['save_pretrained', 'from_pretrained'], 'FeatureExtractionMixin': ['save_pretrained', 'from_pretrained']}.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pipe \u001b[38;5;241m=\u001b[39m \u001b[43mRDMPipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfusing/rdm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\personal_projects\\chi_painting_generator\\diffusers\\src\\diffusers\\pipeline_utils.py:606\u001b[0m, in \u001b[0;36mDiffusionPipeline.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m none_module\u001b[38;5;241m.\u001b[39mstartswith(DUMMY_MODULES_FOLDER) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdummy\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m none_module:\n\u001b[0;32m    603\u001b[0m         \u001b[38;5;66;03m# call class_obj for nice error message of missing requirements\u001b[39;00m\n\u001b[0;32m    604\u001b[0m         class_obj()\n\u001b[1;32m--> 606\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    607\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe component \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_obj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be loaded as it does not seem to have\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    608\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m any of the loading methods defined in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mALL_IMPORTABLE_CLASSES\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    609\u001b[0m     )\n\u001b[0;32m    611\u001b[0m load_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(class_obj, load_method_name)\n\u001b[0;32m    612\u001b[0m loading_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31mValueError\u001b[0m: The component <class 'transformers.models.clip.image_processing_clip.CLIPImageProcessor'> of <class 'diffusers.pipelines.rdm.pipeline_rdm.RDMPipeline'> cannot be loaded as it does not seem to have any of the loading methods defined in {'ModelMixin': ['save_pretrained', 'from_pretrained'], 'SchedulerMixin': ['save_config', 'from_config'], 'DiffusionPipeline': ['save_pretrained', 'from_pretrained'], 'OnnxRuntimeModel': ['save_pretrained', 'from_pretrained'], 'PreTrainedTokenizer': ['save_pretrained', 'from_pretrained'], 'PreTrainedTokenizerFast': ['save_pretrained', 'from_pretrained'], 'PreTrainedModel': ['save_pretrained', 'from_pretrained'], 'FeatureExtractionMixin': ['save_pretrained', 'from_pretrained']}."
     ]
    }
   ],
   "source": [
    "pipe = RDMPipeline.from_pretrained(\"fusing/rdm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b30339",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
