=================================== FAILURES ===================================
___________________ PipelineTesterMixin.test_smart_download ____________________
[gw3] darwin -- Python 3.9.7 /Users/stutiraizada/opt/anaconda3/bin/python

cls = <class 'diffusers.pipeline_utils.DiffusionPipeline'>
pretrained_model_name_or_path = 'hf-internal-testing/unet-pipeline-dummy'
kwargs = {}
cache_dir = '/var/folders/w5/_gxjdr416b3_7wxpxxqv_2xh0000gn/T/tmp10fk1l6f'
force_download = False, resume_download = False, proxies = None
use_auth_token = None, local_files_only = False, revision = None

    @classmethod
    def get_config_dict(
        cls, pretrained_model_name_or_path: Union[str, os.PathLike], **kwargs
    ) -> Tuple[Dict[str, Any], Dict[str, Any]]:
        cache_dir = kwargs.pop("cache_dir", DIFFUSERS_CACHE)
        force_download = kwargs.pop("force_download", False)
        resume_download = kwargs.pop("resume_download", False)
        proxies = kwargs.pop("proxies", None)
        use_auth_token = kwargs.pop("use_auth_token", None)
        local_files_only = kwargs.pop("local_files_only", False)
        revision = kwargs.pop("revision", None)
        _ = kwargs.pop("mirror", None)
        subfolder = kwargs.pop("subfolder", None)
    
        user_agent = {"file_type": "config"}
    
        pretrained_model_name_or_path = str(pretrained_model_name_or_path)
    
        if cls.config_name is None:
            raise ValueError(
                "`self.config_name` is not defined. Note that one should not load a config from "
                "`ConfigMixin`. Please make sure to define `config_name` in a class inheriting from `ConfigMixin`"
            )
    
        if os.path.isfile(pretrained_model_name_or_path):
            config_file = pretrained_model_name_or_path
        elif os.path.isdir(pretrained_model_name_or_path):
            if os.path.isfile(os.path.join(pretrained_model_name_or_path, cls.config_name)):
                # Load from a PyTorch checkpoint
                config_file = os.path.join(pretrained_model_name_or_path, cls.config_name)
            elif subfolder is not None and os.path.isfile(
                os.path.join(pretrained_model_name_or_path, subfolder, cls.config_name)
            ):
                config_file = os.path.join(pretrained_model_name_or_path, subfolder, cls.config_name)
            else:
                raise EnvironmentError(
                    f"Error no file named {cls.config_name} found in directory {pretrained_model_name_or_path}."
                )
        else:
            try:
                # Load from URL or cache if already cached
>               config_file = hf_hub_download(
                    pretrained_model_name_or_path,
                    filename=cls.config_name,
                    cache_dir=cache_dir,
                    force_download=force_download,
                    proxies=proxies,
                    resume_download=resume_download,
                    local_files_only=local_files_only,
                    use_auth_token=use_auth_token,
                    user_agent=user_agent,
                    subfolder=subfolder,
                    revision=revision,
                )

src/diffusers/configuration_utils.py:223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

repo_id = 'hf-internal-testing/unet-pipeline-dummy'
filename = 'model_index.json'

    def hf_hub_download(
        repo_id: str,
        filename: str,
        *,
        subfolder: Optional[str] = None,
        repo_type: Optional[str] = None,
        revision: Optional[str] = None,
        library_name: Optional[str] = None,
        library_version: Optional[str] = None,
        cache_dir: Union[str, Path, None] = None,
        user_agent: Union[Dict, str, None] = None,
        force_download: Optional[bool] = False,
        force_filename: Optional[str] = None,
        proxies: Optional[Dict] = None,
        etag_timeout: Optional[float] = 10,
        resume_download: Optional[bool] = False,
        use_auth_token: Union[bool, str, None] = None,
        local_files_only: Optional[bool] = False,
        legacy_cache_layout: Optional[bool] = False,
    ):
        """Download a given file if it's not already present in the local cache.
    
        The new cache file layout looks like this:
        - The cache directory contains one subfolder per repo_id (namespaced by repo type)
        - inside each repo folder:
            - refs is a list of the latest known revision => commit_hash pairs
            - blobs contains the actual file blobs (identified by their git-sha or sha256, depending on
              whether they're LFS files or not)
            - snapshots contains one subfolder per commit, each "commit" contains the subset of the files
              that have been resolved at that particular commit. Each filename is a symlink to the blob
              at that particular commit.
    
        ```
        [  96]  .
        └── [ 160]  models--julien-c--EsperBERTo-small
            ├── [ 160]  blobs
            │   ├── [321M]  403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
            │   ├── [ 398]  7cb18dc9bafbfcf74629a4b760af1b160957a83e
            │   └── [1.4K]  d7edf6bd2a681fb0175f7735299831ee1b22b812
            ├── [  96]  refs
            │   └── [  40]  main
            └── [ 128]  snapshots
                ├── [ 128]  2439f60ef33a0d46d85da5001d52aeda5b00ce9f
                │   ├── [  52]  README.md -> ../../blobs/d7edf6bd2a681fb0175f7735299831ee1b22b812
                │   └── [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
                └── [ 128]  bbc77c8132af1cc5cf678da3f1ddf2de43606d48
                    ├── [  52]  README.md -> ../../blobs/7cb18dc9bafbfcf74629a4b760af1b160957a83e
                    └── [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
        ```
    
        Args:
            repo_id (`str`):
                A user or an organization name and a repo name separated by a `/`.
            filename (`str`):
                The name of the file in the repo.
            subfolder (`str`, *optional*):
                An optional value corresponding to a folder inside the model repo.
            repo_type (`str`, *optional*):
                Set to `"dataset"` or `"space"` if uploading to a dataset or space,
                `None` or `"model"` if uploading to a model. Default is `None`.
            revision (`str`, *optional*):
                An optional Git revision id which can be a branch name, a tag, or a
                commit hash.
            library_name (`str`, *optional*):
                The name of the library to which the object corresponds.
            library_version (`str`, *optional*):
                The version of the library.
            cache_dir (`str`, `Path`, *optional*):
                Path to the folder where cached files are stored.
            user_agent (`dict`, `str`, *optional*):
                The user-agent info in the form of a dictionary or a string.
            force_download (`bool`, *optional*, defaults to `False`):
                Whether the file should be downloaded even if it already exists in
                the local cache.
            proxies (`dict`, *optional*):
                Dictionary mapping protocol to the URL of the proxy passed to
                `requests.request`.
            etag_timeout (`float`, *optional*, defaults to `10`):
                When fetching ETag, how many seconds to wait for the server to send
                data before giving up which is passed to `requests.request`.
            resume_download (`bool`, *optional*, defaults to `False`):
                If `True`, resume a previously interrupted download.
            use_auth_token (`str`, `bool`, *optional*):
                A token to be used for the download.
                    - If `True`, the token is read from the HuggingFace config
                      folder.
                    - If a string, it's used as the authentication token.
            local_files_only (`bool`, *optional*, defaults to `False`):
                If `True`, avoid downloading the file and return the path to the
                local cached file if it exists.
            legacy_cache_layout (`bool`, *optional*, defaults to `False`):
                If `True`, uses the legacy file cache layout i.e. just call [`hf_hub_url`]
                then `cached_download`. This is deprecated as the new cache layout is
                more powerful.
    
        Returns:
            Local path (string) of file or if networking is off, last version of
            file cached on disk.
    
        <Tip>
    
        Raises the following errors:
    
            - [`EnvironmentError`](https://docs.python.org/3/library/exceptions.html#EnvironmentError)
              if `use_auth_token=True` and the token cannot be found.
            - [`OSError`](https://docs.python.org/3/library/exceptions.html#OSError)
              if ETag cannot be determined.
            - [`ValueError`](https://docs.python.org/3/library/exceptions.html#ValueError)
              if some parameter value is invalid
            - [`~utils.RepositoryNotFoundError`]
              If the repository to download from cannot be found. This may be because it doesn't exist,
              or because it is set to `private` and you do not have access.
            - [`~utils.RevisionNotFoundError`]
              If the revision to download from cannot be found.
            - [`~utils.EntryNotFoundError`]
              If the file to download cannot be found.
            - [`~utils.LocalEntryNotFoundError`]
              If network is disabled or unavailable and file is not found in cache.
    
        </Tip>
        """
        if force_filename is not None:
            warnings.warn(
                "The `force_filename` parameter is deprecated as a new caching system, "
                "which keeps the filenames as they are on the Hub, is now in place.",
                FutureWarning,
            )
            legacy_cache_layout = True
    
        if legacy_cache_layout:
            url = hf_hub_url(
                repo_id,
                filename,
                subfolder=subfolder,
                repo_type=repo_type,
                revision=revision,
            )
    
            return cached_download(
                url,
                library_name=library_name,
                library_version=library_version,
                cache_dir=cache_dir,
                user_agent=user_agent,
                force_download=force_download,
                force_filename=force_filename,
                proxies=proxies,
                etag_timeout=etag_timeout,
                resume_download=resume_download,
                use_auth_token=use_auth_token,
                local_files_only=local_files_only,
                legacy_cache_layout=legacy_cache_layout,
            )
    
        if cache_dir is None:
            cache_dir = HUGGINGFACE_HUB_CACHE
        if revision is None:
            revision = DEFAULT_REVISION
        if isinstance(cache_dir, Path):
            cache_dir = str(cache_dir)
    
        if subfolder == "":
            subfolder = None
        if subfolder is not None:
            # This is used to create a URL, and not a local path, hence the forward slash.
            filename = f"{subfolder}/{filename}"
    
        if repo_type is None:
            repo_type = "model"
        if repo_type not in REPO_TYPES:
            raise ValueError(
                f"Invalid repo type: {repo_type}. Accepted repo types are:"
                f" {str(REPO_TYPES)}"
            )
    
        storage_folder = os.path.join(
            cache_dir, repo_folder_name(repo_id=repo_id, repo_type=repo_type)
        )
        os.makedirs(storage_folder, exist_ok=True)
    
        # cross platform transcription of filename, to be used as a local file path.
        relative_filename = os.path.join(*filename.split("/"))
    
        # if user provides a commit_hash and they already have the file on disk,
        # shortcut everything.
        if REGEX_COMMIT_HASH.match(revision):
            pointer_path = os.path.join(
                storage_folder, "snapshots", revision, relative_filename
            )
            if os.path.exists(pointer_path):
                return pointer_path
    
        url = hf_hub_url(repo_id, filename, repo_type=repo_type, revision=revision)
    
        headers = build_hf_headers(
            use_auth_token=use_auth_token,
            library_name=library_name,
            library_version=library_version,
            user_agent=user_agent,
        )
    
        url_to_download = url
        etag = None
        commit_hash = None
        if not local_files_only:
            try:
                try:
                    metadata = get_hf_file_metadata(
                        url=url,
                        use_auth_token=use_auth_token,
                        proxies=proxies,
                        timeout=etag_timeout,
                    )
                except EntryNotFoundError as http_error:
                    # Cache the non-existence of the file and raise
                    commit_hash = http_error.response.headers.get(
                        HUGGINGFACE_HEADER_X_REPO_COMMIT
                    )
                    if commit_hash is not None and not legacy_cache_layout:
                        no_exist_file_path = (
                            Path(storage_folder)
                            / ".no_exist"
                            / commit_hash
                            / relative_filename
                        )
                        no_exist_file_path.parent.mkdir(parents=True, exist_ok=True)
                        no_exist_file_path.touch()
                        _cache_commit_hash_for_specific_revision(
                            storage_folder, revision, commit_hash
                        )
                    raise
    
                # Commit hash must exist
                commit_hash = metadata.commit_hash
                if commit_hash is None:
                    raise OSError(
                        "Distant resource does not seem to be on huggingface.co (missing"
                        " commit header)."
                    )
    
                # Etag must exist
                etag = metadata.etag
                # We favor a custom header indicating the etag of the linked resource, and
                # we fallback to the regular etag header.
                # If we don't have any of those, raise an error.
                if etag is None:
                    raise OSError(
                        "Distant resource does not have an ETag, we won't be able to"
                        " reliably ensure reproducibility."
                    )
    
                # In case of a redirect, save an extra redirect on the request.get call,
                # and ensure we download the exact atomic version even if it changed
                # between the HEAD and the GET (unlikely, but hey).
                # Useful for lfs blobs that are stored on a CDN.
                if metadata.location != url:
                    url_to_download = metadata.location
                    if (
                        "lfs.huggingface.co" in url_to_download
                        or "lfs-staging.huggingface.co" in url_to_download
                    ):
                        # Remove authorization header when downloading a LFS blob
                        headers.pop("authorization", None)
            except (requests.exceptions.SSLError, requests.exceptions.ProxyError):
                # Actually raise for those subclasses of ConnectionError
                raise
            except (
                requests.exceptions.ConnectionError,
                requests.exceptions.Timeout,
                OfflineModeIsEnabled,
            ):
                # Otherwise, our Internet connection is down.
                # etag is None
                pass
    
        # etag is None == we don't have a connection or we passed local_files_only.
        # try to get the last downloaded one from the specified revision.
        # If the specified revision is a commit hash, look inside "snapshots".
        # If the specified revision is a branch or tag, look inside "refs".
        if etag is None:
            # In those cases, we cannot force download.
            if force_download:
                raise ValueError(
                    "We have no connection or you passed local_files_only, so"
                    " force_download is not an accepted option."
                )
            if REGEX_COMMIT_HASH.match(revision):
                commit_hash = revision
            else:
                ref_path = os.path.join(storage_folder, "refs", revision)
>               with open(ref_path) as f:
E               FileNotFoundError: [Errno 2] No such file or directory: '/var/folders/w5/_gxjdr416b3_7wxpxxqv_2xh0000gn/T/tmp10fk1l6f/models--hf-internal-testing--unet-pipeline-dummy/refs/main'

../../../opt/anaconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1136: FileNotFoundError

During handling of the above exception, another exception occurred:

self = <tests.test_pipelines.PipelineTesterMixin testMethod=test_smart_download>

>   ???

tests/test_pipelines.py:1405: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/diffusers/pipeline_utils.py:366: in from_pretrained
    if not os.path.isdir(pretrained_model_name_or_path):
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'diffusers.pipeline_utils.DiffusionPipeline'>
pretrained_model_name_or_path = 'hf-internal-testing/unet-pipeline-dummy'
kwargs = {}
cache_dir = '/var/folders/w5/_gxjdr416b3_7wxpxxqv_2xh0000gn/T/tmp10fk1l6f'
force_download = False, resume_download = False, proxies = None
use_auth_token = None, local_files_only = False, revision = None

    @classmethod
    def get_config_dict(
        cls, pretrained_model_name_or_path: Union[str, os.PathLike], **kwargs
    ) -> Tuple[Dict[str, Any], Dict[str, Any]]:
        cache_dir = kwargs.pop("cache_dir", DIFFUSERS_CACHE)
        force_download = kwargs.pop("force_download", False)
        resume_download = kwargs.pop("resume_download", False)
        proxies = kwargs.pop("proxies", None)
        use_auth_token = kwargs.pop("use_auth_token", None)
        local_files_only = kwargs.pop("local_files_only", False)
        revision = kwargs.pop("revision", None)
        _ = kwargs.pop("mirror", None)
        subfolder = kwargs.pop("subfolder", None)
    
        user_agent = {"file_type": "config"}
    
        pretrained_model_name_or_path = str(pretrained_model_name_or_path)
    
        if cls.config_name is None:
            raise ValueError(
                "`self.config_name` is not defined. Note that one should not load a config from "
                "`ConfigMixin`. Please make sure to define `config_name` in a class inheriting from `ConfigMixin`"
            )
    
        if os.path.isfile(pretrained_model_name_or_path):
            config_file = pretrained_model_name_or_path
        elif os.path.isdir(pretrained_model_name_or_path):
            if os.path.isfile(os.path.join(pretrained_model_name_or_path, cls.config_name)):
                # Load from a PyTorch checkpoint
                config_file = os.path.join(pretrained_model_name_or_path, cls.config_name)
            elif subfolder is not None and os.path.isfile(
                os.path.join(pretrained_model_name_or_path, subfolder, cls.config_name)
            ):
                config_file = os.path.join(pretrained_model_name_or_path, subfolder, cls.config_name)
            else:
                raise EnvironmentError(
                    f"Error no file named {cls.config_name} found in directory {pretrained_model_name_or_path}."
                )
        else:
            try:
                # Load from URL or cache if already cached
                config_file = hf_hub_download(
                    pretrained_model_name_or_path,
                    filename=cls.config_name,
                    cache_dir=cache_dir,
                    force_download=force_download,
                    proxies=proxies,
                    resume_download=resume_download,
                    local_files_only=local_files_only,
                    use_auth_token=use_auth_token,
                    user_agent=user_agent,
                    subfolder=subfolder,
                    revision=revision,
                )
    
            except RepositoryNotFoundError:
                raise EnvironmentError(
                    f"{pretrained_model_name_or_path} is not a local folder and is not a valid model identifier"
                    " listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a"
                    " token having permission to this repo with `use_auth_token` or log in with `huggingface-cli"
                    " login`."
                )
            except RevisionNotFoundError:
                raise EnvironmentError(
                    f"{revision} is not a valid git identifier (branch name, tag name or commit id) that exists for"
                    " this model name. Check the model page at"
                    f" 'https://huggingface.co/{pretrained_model_name_or_path}' for available revisions."
                )
            except EntryNotFoundError:
                raise EnvironmentError(
                    f"{pretrained_model_name_or_path} does not appear to have a file named {cls.config_name}."
                )
            except HTTPError as err:
                raise EnvironmentError(
                    "There was a specific connection error when trying to load"
                    f" {pretrained_model_name_or_path}:\n{err}"
                )
            except ValueError:
                raise EnvironmentError(
                    f"We couldn't connect to '{HUGGINGFACE_CO_RESOLVE_ENDPOINT}' to load this model, couldn't find it"
                    f" in the cached files and it looks like {pretrained_model_name_or_path} is not the path to a"
                    f" directory containing a {cls.config_name} file.\nCheckout your internet connection or see how to"
                    " run the library in offline mode at"
                    " 'https://huggingface.co/docs/diffusers/installation#offline-mode'."
                )
            except EnvironmentError:
>               raise EnvironmentError(
                    f"Can't load config for '{pretrained_model_name_or_path}'. If you were trying to load it from "
                    "'https://huggingface.co/models', make sure you don't have a local directory with the same name. "
                    f"Otherwise, make sure '{pretrained_model_name_or_path}' is the correct path to a directory "
                    f"containing a {cls.config_name} file"
                )
E               OSError: Can't load config for 'hf-internal-testing/unet-pipeline-dummy'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'hf-internal-testing/unet-pipeline-dummy' is the correct path to a directory containing a model_index.json file

src/diffusers/configuration_utils.py:268: OSError
